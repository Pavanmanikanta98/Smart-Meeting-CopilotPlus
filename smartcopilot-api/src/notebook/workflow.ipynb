{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d4347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94016127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5336268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b9fd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Any, TypedDict, Literal, List, Optional\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8134d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "950b3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Storage ---\n",
    "# This class simulates a database or key-value store.\n",
    "# In production, this could be replaced with Redis, a file system, or a database.\n",
    "class DataStorage:\n",
    "    \"\"\"Simulates a database. In production, replace with Redis, a DB, etc.\"\"\"\n",
    "    _storage = {\n",
    "        'document_content': {},\n",
    "        'summary_output': {},\n",
    "        'insights_output': {},\n",
    "        'action_items': {}\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def store(cls, data_type: str, data: any) -> str:\n",
    "        \"\"\"Store data and return a unique reference ID.\"\"\"\n",
    "        # Using a simple timestamp and random number for a unique ID\n",
    "        uid = f\"{data_type}_{int(time.time() * 1000)}_{random.randint(100, 999)}\"\n",
    "        cls._storage[data_type][uid] = data\n",
    "        print(f\"üì¶ Stored data of type '{data_type}' with ID: {uid}\")\n",
    "        return uid\n",
    "    \n",
    "    @classmethod\n",
    "    def retrieve(cls, data_type: str, uid: str) -> any:\n",
    "        \"\"\"Retrieve data by its reference ID.\"\"\"\n",
    "        print(f\" retrievel data of type '{data_type}' with ID: {uid}\")\n",
    "        return cls._storage[data_type].get(uid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b8ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7ea4696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Refactored GraphState ---\n",
    "# The state now holds lightweight IDs instead of large text blobs.\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"Refactored state using IDs for scalability.\"\"\"\n",
    "    document_content_id: str\n",
    "    summary_status: str\n",
    "    insights_status: str\n",
    "    summary_id: Optional[str]\n",
    "    insights_id: Optional[str]\n",
    "    action_items_id: Optional[str]\n",
    "    iteration: int\n",
    "    error_message: str\n",
    "    current_reasoning: str\n",
    "    next: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "79ab7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Item Extraction Tool \n",
    "class ActionItem(BaseModel):\n",
    "    task: str = Field(description=\"The specific action or task to be completed.\")\n",
    "    owner: Optional[str] = Field(description=\"The person or team responsible for the task.\")\n",
    "    deadline: Optional[str] = Field(description=\"The due date for the task, e.g., 'EOW', '2024-08-15'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3a560b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Simple but intelligent decision model\n",
    "class SupervisorDecision(BaseModel):\n",
    "    \"\"\"AI Supervisor decision with intelligent reasoning\"\"\"\n",
    "    next_action: Literal[\n",
    "        \"call_both_parallel\", \n",
    "        \"call_summary_only\", \n",
    "        \"call_insights_only\", \n",
    "        \"end_workflow\"\n",
    "    ] = Field(description=\"What to do next in the workflow\")\n",
    "    \n",
    "    reasoning: str = Field(description=\"Why this decision makes sense for the workflow goal\")\n",
    "    \n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence in this decision (0.0 to 1.0)\", \n",
    "        ge=0.0, le=1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a6838fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"extract_and_store_action_items\", return_direct=True)\n",
    "def extract_and_store_action_items(document_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Identifies action items in a document, structures them,\n",
    "    stores them, and returns a confirmation with the storage ID.\n",
    "    \"\"\"\n",
    "    print(\"\\nüõ†Ô∏è Action Item Tool Called...\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert at extracting structured data. Identify all action items from the text. For each, extract the task, owner, and deadline. Use 'N/A' if missing.\"),\n",
    "        (\"human\", \"Extract action items from this document:\\n\\n---\\n\\n{document}\")\n",
    "    ])\n",
    "    llm = ChatGroq(temperature=0, model=\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "    # # Use with_structured_output to get clean JSON\n",
    "    # extractor = prompt | llm.with_structured_output(schema=List[ActionItem])\n",
    "\n",
    "    # This correctly defines the schema for a list of items\n",
    "    class ActionItems(BaseModel):\n",
    "        action_items: List[ActionItem]\n",
    "\n",
    "    extractor = prompt | llm.with_structured_output(schema=ActionItems)\n",
    "\n",
    "    try:\n",
    "        # The result will be an instance of the ActionItems class\n",
    "        result = extractor.invoke({\"document\": document_content})\n",
    "\n",
    "        action_items_list = result.action_items if result and hasattr(result, \"action_items\") else []\n",
    "        \n",
    "        # if not result.action_items:\n",
    "        #     return \"No action items were found in the document.\"\n",
    "\n",
    "        if not action_items_list:\n",
    "            return \"No action items were found in the document.\"\n",
    "\n",
    "        # Store the list of Pydantic objects\n",
    "        storage_id = DataStorage.store('action_items', action_items_list)\n",
    "        print(f\"‚úÖ Action items extracted and stored successfully.\")\n",
    "        \n",
    "        # Return a structured confirmation message\n",
    "        return f\"Confirmation: Successfully stored {len(action_items_list)} action items with ID {storage_id}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Action Item Tool: {e}\")\n",
    "        return \"An error occurred during action item extraction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1af35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def intelligent_supervisor(state: GraphState) ->  Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Smart supervisor that understands the workflow goal:\n",
    "    - Get meeting minutes summary \n",
    "    - Get key insights in parallel\n",
    "    - Be intelligent about when to retry vs when to finish\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß† AI Supervisor thinking... (Iteration: {state['iteration']})\")\n",
    "    \n",
    "    # Enhanced ReAct-style system prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are an intelligent workflow supervisor using ReAct (Reasoning + Acting) methodology. \n",
    "\n",
    "    ## YOUR MISSION:\n",
    "    Ensure we successfully get a meeting summary and key insights stored efficiently.\n",
    "\n",
    "    ## ReAct PROCESS - Think step by step:\n",
    "    **THOUGHT**: First, analyze the current workflow state. What's working? What failed? Why might it have failed?\n",
    "    **OBSERVATION**: A task is 'successful' if its status is 'success' AND its ID exists. A task has 'failed' if its status is 'failed'.\n",
    "    **ACTION**: Based on your thought and observation, decide the smartest next action.\n",
    "\n",
    "    ## CURRENT WORKFLOW STATE:\n",
    "    - Summary Status: {summary_status} (summary_id: {summary_id})\n",
    "    - Insights Status: {insights_status} (insights_id: {insights_id})\n",
    "    - Action Items Found: {action_items_count}\n",
    "    - Current Iteration: {iteration}\n",
    "    - Last Error: {error_msg}\n",
    "\n",
    "    ## AVAILABLE ACTIONS:\n",
    "    - call_both_parallel: Run both agents simultaneously.\n",
    "    - call_summary_only: Focus only on getting the summary.\n",
    "    - call_insights_only: Focus only on getting insights.  \n",
    "    - end_workflow: Use this ONLY when both Summary and Insights have a 'success' status and their IDs exist.\n",
    "\n",
    "    ## INTELLIGENT DECISION GUIDELINES:\n",
    "    - Iteration 1: Usually start with parallel execution for efficiency.\n",
    "    - One success, one failure: Target retry on the failed agent only.\n",
    "    - Both failed in early iterations: Likely a temporary issue, retry both.\n",
    "    - Multiple failures: Consider if we should accept partial results or end the workflow.\n",
    "    - Both successful: Mission accomplished! Time to end the workflow.\n",
    "\n",
    "    **Remember**: You're optimizing for getting useful meeting analysis (summary + insights), not just perfect success rates.\n",
    "\n",
    "    Use the ReAct process: THOUGHT ‚Üí OBSERVATION ‚Üí ACTION with clear reasoning.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"state:\", state)\n",
    "    \n",
    "     # FIX: The formatting logic now uses the correct 'summary_id' and 'insights_id' keys from the state.\n",
    "    formatted_prompt = system_prompt.format(\n",
    "        summary_status=state['summary_status'],\n",
    "        summary_id=f\"'{state['summary_id']}'\" if state.get('summary_id') else \"None\",\n",
    "        insights_status=state['insights_status'],\n",
    "        insights_id=f\"'{state['insights_id']}'\" if state.get('insights_id') else \"None\",\n",
    "        # action_items_count=len(state.get('action_items_id')),\n",
    "        iteration=state['iteration'],\n",
    "        error_msg=state.get('error_message') or \"None\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Setup Groq API with Qwen model\n",
    "    groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "    \n",
    "    os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        temperature=0,\n",
    "        model=\"deepseek-r1-distill-llama-70b\"  \n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Use ReAct methodology: THOUGHT ‚Üí OBSERVATION ‚Üí ACTION. Analyze the workflow state and decide what to do next for our goal. Think step by step.\")\n",
    "    ]\n",
    "    \n",
    "    # Get structured decision from LLM\n",
    "    try:\n",
    "        decision = llm.with_structured_output(SupervisorDecision).invoke(messages)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM call failed: {e}\")\n",
    "        # Fallback to simulation if LLM fails\n",
    "        decision = simulate_smart_decision(state)\n",
    "    \n",
    "    # # Simulate intelligent decision (replace with real LLM)\n",
    "    # decision = simulate_smart_decision(state)\n",
    "    \n",
    "    print(f\"üí≠ AI Reasoning: {decision.reasoning}\")\n",
    "    print(f\"‚ö° Decision: {decision.next_action} (confidence: {decision.confidence:.2f})\")\n",
    "    \n",
    "    # # Update state with AI reasoning\n",
    "    # new_state = state.copy()\n",
    "    # new_state['next'] = decision.next_action  # Store the next action\n",
    "    # new_state['current_reasoning'] = decision.reasoning\n",
    "    \n",
    "    # return decision.next_action if decision.next_action != \"end_workflow\" else END\n",
    "    goto = decision.next_action if decision.next_action != \"end_workflow\" else END\n",
    "\n",
    "    print('goto:',goto)\n",
    "\n",
    "    return {\n",
    "        \"current_reasoning\": decision.reasoning,\n",
    "        \"next\": decision.next_action # Store the determined next action\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "38bc4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simulate_smart_decision(state: GraphState) -> SupervisorDecision:\n",
    "    \"\"\"\n",
    "    Simulate what an intelligent model like Qwen would decide\n",
    "    This is just simulation - replace with actual LLM call\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_status = state['summary_status']\n",
    "    insights_status = state['insights_status']\n",
    "    iteration = state['iteration']\n",
    "    \n",
    "    # Smart decision making that a good reasoning model would do\n",
    "    \n",
    "    # Goal achieved - both successful\n",
    "    if summary_status == \"success\" and insights_status == \"success\":\n",
    "        return SupervisorDecision(\n",
    "            next_action=\"end_workflow\",\n",
    "            reasoning=\"Perfect! Both summary and insights are ready. Our workflow goal is complete - we have meeting summary + key insights as requested.\",\n",
    "            confidence=1.0\n",
    "        )\n",
    "    \n",
    "    # First iteration - start efficiently  \n",
    "    if iteration == 1 and summary_status == \"pending\" and insights_status == \"pending\":\n",
    "        return SupervisorDecision(\n",
    "            next_action=\"call_both_parallel\", \n",
    "            reasoning=\"First attempt - running both summary and insights agents in parallel for efficiency. This is the optimal starting strategy.\",\n",
    "            confidence=0.9\n",
    "        )\n",
    "    \n",
    "    # One succeeded, one failed - targeted retry\n",
    "    if summary_status == \"success\" and insights_status == \"failed\":\n",
    "        if iteration <= 3:  # Smart about retry limits\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_insights_only\",\n",
    "                reasoning=\"Summary is ready, but insights failed. Retrying only insights agent since summary is already successful. Efficient targeted approach.\",\n",
    "                confidence=0.8\n",
    "            )\n",
    "        else:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"end_workflow\",\n",
    "                reasoning=\"Summary is ready and we've tried insights multiple times. Sometimes partial success is acceptable for meeting processing workflow.\",\n",
    "                confidence=0.6\n",
    "            )\n",
    "    \n",
    "    if insights_status == \"success\" and summary_status == \"failed\":\n",
    "        if iteration <= 3:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_summary_only\", \n",
    "                reasoning=\"Insights are ready, but summary failed. Retrying only summary agent since insights are already successful. Focused retry approach.\",\n",
    "                confidence=0.8\n",
    "            )\n",
    "        else:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"end_workflow\",\n",
    "                reasoning=\"Insights are ready and we've tried summary multiple times. We have key insights from the meeting which provides value.\",\n",
    "                confidence=0.6\n",
    "            )\n",
    "    \n",
    "    # Both failed - intelligent retry decision\n",
    "    if summary_status == \"failed\" and insights_status == \"failed\":\n",
    "        if iteration <= 2:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_both_parallel\",\n",
    "                reasoning=\"Both agents failed, but it's early in the process. Likely a temporary issue (network/API). Retrying both in parallel - efficient recovery approach.\",\n",
    "                confidence=0.7\n",
    "            )\n",
    "        elif iteration <= 4:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_both_parallel\", \n",
    "                reasoning=\"Multiple failures but still within reasonable retry range. The meeting document seems valid, so this might be temporary service issues. One more parallel attempt.\",\n",
    "                confidence=0.5\n",
    "            )\n",
    "        else:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"end_workflow\",\n",
    "                reasoning=\"After multiple attempts, continuing may not be productive. This could be a deeper issue with the document format or service availability. Ending workflow.\",\n",
    "                confidence=0.8\n",
    "            )\n",
    "    \n",
    "    # Default intelligent fallback\n",
    "    return SupervisorDecision(\n",
    "        next_action=\"call_both_parallel\",\n",
    "        reasoning=\"Current state requires both agents to run. Taking parallel approach for efficiency in meeting processing workflow.\", \n",
    "        confidence=0.6\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "684ebd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_supervisor_decision(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the decision stored by the intelligent supervisor.\n",
    "    \"\"\"\n",
    "    return state['next'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "04071fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_summary_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     An agentic node that intelligently generates a meeting summary.\n",
    "#     It has a specific persona, instructions, and robust error handling.\n",
    "#     \"\"\"\n",
    "#     print(\"\\nü§ñ Agentic Summary Node Called...\")\n",
    "\n",
    "#     # 1. Define the Agent's Persona and Mission via a System Prompt\n",
    "#     system_prompt = \"\"\"\n",
    "#     You are an expert Meeting Summarization Agent. Your sole mission is to create a concise, structured, and insightful summary from the provided meeting minutes.\n",
    "#     If you identify any specific tasks assigned to people (action items), Do include the action items directly in your final summary. Also, you MUST use the 'extract_and_store_action_items' tool to process them. you can mention that action items were noted and processed separately.\n",
    "    \n",
    "#     You have access to the following tools to help you:\n",
    "#     {tools}\n",
    "    \n",
    "#     Tool Names: {tool_names}\n",
    "\n",
    "#     ## Your Guidelines:\n",
    "#     1.  **Identify Core Content**: Focus on extracting the most critical information:\n",
    "#         - **Key Decisions Made**: What was formally decided?\n",
    "#         - **Action Items**: What are the specific next steps? Who is responsible (owner)? What are the deadlines?\n",
    "#         - **Major Topics Discussed**: Briefly mention the main subjects of conversation.\n",
    "#         - **Outcomes & Resolutions**: What was the final result of the discussions?\n",
    "\n",
    "#     2.  **Prioritize Significance**: Do not just list topics in order. Your value is in identifying what truly matters. A brief 2-minute decision that sets the company's direction is more important than a 30-minute unresolved debate.\n",
    "\n",
    "#     3.  **Structure the Output**: Present the summary in a clean, professional format using Markdown. Use headings (#), subheadings (##), and bullet points (-) for clarity.\n",
    "\n",
    "#     4.  **Be Objective**: Summarize what was said and decided without adding your own opinions or interpretations. Stick to the facts presented in the document.\n",
    "\n",
    "#     Your final output should be ONLY the structured summary, ready to be shared with meeting attendees.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 2. Setup the Agent with proper prompt template\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system_prompt),\n",
    "#         (\"user\", \"{input}\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#     ])\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", \"\"\"\n",
    "#         You are an expert Meeting Summarization Agent. Your sole mission is to create a concise, structured, and insightful summary from the provided meeting minutes.\n",
    "#         Prioritize key decisions, major topics, and outcomes.\n",
    "#         If you identify any specific tasks assigned to people (action items), you MUST use the 'extract_and_store_action_items' tool to process them.\n",
    "#         Do not list the action items in your final answer; just mention that they were processed separately.\n",
    "\n",
    "#         You have access to the following tools:\n",
    "#         {tools}\n",
    "\n",
    "#         To use a tool, respond with a JSON blob with 'action' and 'action_input' keys. The 'action' must be one of [{tool_names}].\n",
    "#         When you have your final summary, you MUST respond with a JSON blob with a single 'answer' key.\n",
    "#         \"\"\"),\n",
    "#         (\"user\", \"{input}\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#     ])\n",
    "   \n",
    "\n",
    "#     groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "#     if not groq_api_key:\n",
    "#         raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "#     llm = ChatGroq(temperature=0, model=\"qwen/qwen3-32b\")\n",
    "\n",
    "#     # The agent uses the LLM and prompt, with tools for action item extraction\n",
    "#     tools = [extract_and_store_action_items]\n",
    "#     agent = create_react_agent(llm, tools, prompt=prompt)\n",
    "#     summary_agent = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "#     # 3. Invoke the Agent with Error Handling\n",
    "#     try:\n",
    "#         document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "#         if not document_content:\n",
    "#             raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "        \n",
    "#         print(\"üß† Agent is thinking and generating the summary...\")\n",
    "#         # The input to the agent is the document content from DataStorage\n",
    "#         # This allows the agent to work with a lightweight reference ID instead of large text blobs.\n",
    "#         # This is more scalable and efficient for large documents.\n",
    "#         agent_input = {\n",
    "#             \"input\": f\"Please generate a summary for the following meeting minutes:\\n\\n---\\n\\n{document_content}\",\n",
    "#             \"document_content\": document_content \n",
    "#         }\n",
    "#         result = summary_agent.invoke(agent_input)\n",
    "        \n",
    "\n",
    "#         # The agent's final answer is in the output key for ReAct agents\n",
    "#         generated_summary = result.get('output', result['messages'][-1].content if 'messages' in result else str(result))\n",
    "#         print(\"‚úÖ Summary Agent: Generated summary successfully.\")\n",
    "        \n",
    "#         # Store the generated summary\n",
    "#         summary_id = DataStorage.store('summary_output', generated_summary)\n",
    "        \n",
    "#         return {\n",
    "#             \"summary_status\": \"success\",\n",
    "#             \"summary_id\": summary_id,\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in Agentic Summary Node: {e}\")\n",
    "        \n",
    "#         # If the agent fails, report the failure back to the graph state\n",
    "#         return {\n",
    "#             \"summary_status\": \"failed\",\n",
    "#             \"error_message\": f\"Summary Agent Error: {str(e)}\"\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to have the correct imports\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import create_react_agent # Modern agent builder\n",
    "from langchain_core.messages import SystemMessage, ToolMessage\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Assuming GraphState and DataStorage are defined elsewhere, as in your original code\n",
    "# and the tool 'extract_and_store_action_items' is also defined.\n",
    "\n",
    "def run_summary_agent(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    An agentic node that intelligently generates a meeting summary using the\n",
    "    modern langgraph.prebuilt.create_react_agent.\n",
    "    \"\"\"\n",
    "    print(\"\\nü§ñ Modern Agentic Summary Node Called...\")\n",
    "\n",
    "    # 1. Define the Agent's Persona and Mission\n",
    "    # This prompt is simpler because modern tool-calling models don't need\n",
    "    # explicit instructions on JSON formatting.\n",
    "    system_prompt = \"\"\"You are an expert Meeting Summarization Agent. Your sole mission is to create a concise, structured, and insightful summary from the provided meeting minutes.\n",
    "\n",
    "## Your Guidelines:\n",
    "1.  **Core Content**: Focus on key decisions, major topics discussed, and final outcomes.\n",
    "2.  **Tool Use**: If you identify any specific tasks or action items, you MUST use the `extract_and_store_action_items` tool to process them.\n",
    "3.  **Final Output**: In your final answer, do not list the action items . Simply state that they were identified and processed. The final output should ONLY be the clean, Markdown-formatted summary.\n",
    "\"\"\"\n",
    "\n",
    "    # 2. Setup the LLM, Tools, and Agent\n",
    "    try:\n",
    "        groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        if not groq_api_key:\n",
    "            raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "        # Note: Using a powerful model like Llama 3 70b is recommended for complex summarization.\n",
    "        # \"qwen/qwen3-32b\" is not a standard model on the Groq API.\n",
    "        llm = ChatGroq(temperature=0, model=\"qwen/qwen3-32b\")\n",
    "        tools = [extract_and_store_action_items]\n",
    "\n",
    "        # This single line creates the modern, compiled agent graph.\n",
    "        # It replaces both the legacy create_react_agent and the AgentExecutor.\n",
    "        summary_agent_graph = create_react_agent(llm, tools, prompt=system_prompt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during agent setup: {e}\")\n",
    "        return {\n",
    "            \"summary_status\": \"failed\",\n",
    "            \"error_message\": f\"Summary Agent Setup Error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "    # 3. Invoke the Agent with Error Handling\n",
    "    try:\n",
    "        document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "        if not document_content:\n",
    "            raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "\n",
    "        print(\"üß† Agent is thinking and generating the summary...\")\n",
    "\n",
    "        # The input for a langgraph agent is a dictionary with a \"messages\" key.\n",
    "        agent_input = {\n",
    "            \"messages\": [\n",
    "                (\"user\", f\"Please generate a summary for the following meeting minutes:\\n\\n---\\n\\n{document_content}\")\n",
    "            ]\n",
    "        }\n",
    "        result = summary_agent_graph.invoke(agent_input)\n",
    "\n",
    "        # The agent's final answer is the content of the last message in the state.\n",
    "        generated_summary = result[\"messages\"][-1].content\n",
    "        print(\"‚úÖ Summary Agent: Generated summary successfully.:::\", generated_summary)\n",
    "\n",
    "        # action_item_id = None\n",
    "        # for message in result.get(\"messages\", []):\n",
    "        #     # Find the ToolMessage from our specific tool\n",
    "        #     if isinstance(message, ToolMessage) and \"Confirmation: Successfully stored\" in message.content:\n",
    "        #         # Parse the ID from the confirmation string\n",
    "        #         match = re.search(r'ID (\\S+)', message.content)\n",
    "        #         if match:\n",
    "        #             action_item_id = match.group(1)\n",
    "        #             print(f\"‚úÖ Summary node captured Action Item ID: {action_item_id}\")\n",
    "        #             break\n",
    "        \n",
    "\n",
    "        # Store the generated summary\n",
    "        summary_id = DataStorage.store('summary_output', generated_summary)\n",
    "\n",
    "        return {\n",
    "            \"summary_status\": \"success\",\n",
    "            \"summary_id\": summary_id,\n",
    "            \"error_message\": \"\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Agentic Summary Node: {e}\")\n",
    "        return {\n",
    "            \"summary_status\": \"failed\",\n",
    "            \"error_message\": f\"Summary Agent Error: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9de7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "99c2359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to have the correct imports\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "# Assuming GraphState and DataStorage are defined elsewhere\n",
    "\n",
    "def run_insights_agent(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    A specialist node that uses a focused LLM chain to extract deep,\n",
    "    strategic insights from meeting minutes.\n",
    "    \"\"\"\n",
    "    print(\"\\nüí° Specialist Insights Node Called...\")\n",
    "\n",
    "    # 1. Crafting a High-Fidelity Prompt for the Insights Specialist\n",
    "    # This is the heart of the \"agentic\" behavior for a no-tool task.\n",
    "    # We give it a strong persona, a clear mission, and a structured framework.\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        # PERSONA & MISSION\n",
    "        You are a premier Business Strategy Analyst and Insights Specialist. You are not a summarizer; you are a sense-maker. Your mission is to transcend the surface-level details of the provided meeting minutes and distill them into high-level, actionable, strategic insights for executive review. You must uncover the 'why' behind the 'what'.\n",
    "\n",
    "        # ANALYTICAL FRAMEWORK\n",
    "        Read the entire document first. Then, apply the following framework to generate your insights. Do not mention this framework in your output; use it as your internal guide.\n",
    "\n",
    "        1.  **Identify Key Themes**: What are the recurring strategic ideas, concerns, or opportunities being discussed? Look for patterns, not just topics.\n",
    "            - *Example: \"A recurring theme was the tension between innovation speed and maintaining product quality.\"*\n",
    "\n",
    "        2.  **Analyze Critical Decisions & Implications**: For each major decision, state it concisely and then, most importantly, explain its strategic implication.\n",
    "            - *Example: \"Decision: The 'Phoenix Project' was greenlit. Implication: This signals a major strategic pivot for the company, deprioritizing legacy systems to capture a new market segment.\"*\n",
    "\n",
    "        3.  **Surface Actionable Insights**: What can the leadership team learn from the conversation? These are not action items (tasks for individuals), but strategic recommendations for the team or company as a whole.\n",
    "            - *Example: \"Insight: The extended debate over resource allocation for Q4 reveals a potential misalignment on departmental priorities. A cross-departmental priority-setting workshop is recommended.\"*\n",
    "\n",
    "        # OUTPUT REQUIREMENTS\n",
    "        - Your final output must be ONLY the structured insights.\n",
    "        - Use clean, professional Markdown formatting (headings, subheadings, bullet points).\n",
    "        - Do NOT summarize the meeting. Do NOT mention action items. Your focus is exclusively on strategic insights.\n",
    "        - Begin your analysis directly without any preamble like \"Here are the insights...\".\n",
    "\n",
    "        # DOCUMENT FOR ANALYSIS\n",
    "        ---\n",
    "        {document_content}\n",
    "        ---\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "    # 2. Setup a simple, powerful LLM Chain (No agent needed)\n",
    "    try:\n",
    "        groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        if not groq_api_key:\n",
    "            raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "        # A powerful model is essential for this kind of deep reasoning task.\n",
    "        llm = ChatGroq(temperature=0.2, model=\"llama3-70b-8192\")\n",
    "\n",
    "        # This simple LCEL chain is more efficient than an agent for no-tool tasks.\n",
    "        insights_chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during insights chain setup: {e}\")\n",
    "        return {\n",
    "            \"insights_status\": \"failed\",\n",
    "            \"error_message\": f\"Insights Chain Setup Error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "    # 3. Invoke the Chain with Error Handling\n",
    "    try:\n",
    "        document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "        if not document_content:\n",
    "            raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "\n",
    "        print(\"üß† Specialist is analyzing and extracting insights...\")\n",
    "        \n",
    "        # Invoke the chain directly with the document content.\n",
    "        generated_insights = insights_chain.invoke({\"document_content\": document_content})\n",
    "\n",
    "        print(\"‚úÖ Insights Specialist: Extracted insights successfully.\", generated_insights)\n",
    "\n",
    "        # Store the generated insights\n",
    "        insights_id = DataStorage.store('insights_output', generated_insights)\n",
    "\n",
    "        return {\n",
    "            \"insights_status\": \"success\",\n",
    "            \"insights_id\": insights_id,\n",
    "            \"error_message\": \"\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Specialist Insights Node: {e}\")\n",
    "        return {\n",
    "            \"insights_status\": \"failed\",\n",
    "            \"error_message\": f\"Insights Specialist Error: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5d6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "304047ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_both_parallel_agents(state: GraphState) -> dict:\n",
    "    \"\"\"Runs the refactored summary and insights agents in parallel.\"\"\"\n",
    "    print(\"\\n---RUNNING BOTH REFACTORED AGENTS IN PARALLEL---\")\n",
    "\n",
    "    parallel_runnable = RunnableParallel(\n",
    "        summary_result=run_summary_agent,\n",
    "        insights_result=run_insights_agent\n",
    "    )\n",
    "    parallel_results = parallel_runnable.invoke(state)\n",
    "    \n",
    "    # This combination logic remains the same and works with the new outputs\n",
    "    return {**parallel_results['summary_result'], **parallel_results['insights_result']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4373f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_iteration(state: GraphState) -> GraphState:\n",
    "    \"\"\"Track iterations for intelligent decision making\"\"\"\n",
    "    new_state = state.copy()\n",
    "    new_state['iteration'] += 1\n",
    "    print(f\"\\n--- Workflow Iteration: {new_state['iteration']} ---\")\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c1b789c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7aaf4751ddc0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the workflow graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"increment_iteration\", increment_iteration)\n",
    "workflow.add_node(\"intelligent_supervisor\", intelligent_supervisor)\n",
    "workflow.add_node(\"run_summary_agent\", run_summary_agent)\n",
    "workflow.add_node(\"run_insights_agent\", run_insights_agent)\n",
    "workflow.add_node(\"run_parallel_agents\", run_both_parallel_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "46e59386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7aaf4751ddc0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"increment_iteration\")\n",
    "\n",
    "# Define initial edge from entry point to supervisor\n",
    "workflow.add_edge(\"increment_iteration\", \"intelligent_supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4bad92f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7aaf4751ddc0>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The AI supervisor makes intelligent routing decisions\n",
    "# - The edge starts from the 'intelligent_supervisor' node.\n",
    "# - The 'route_supervisor_decision' function defines how to choose the next path.\n",
    "workflow.add_conditional_edges(\n",
    "    \"intelligent_supervisor\",     # Conditional edges originate from the 'intelligent_supervisor' node\n",
    "    route_supervisor_decision,    # This function defines the routing logic (returns the key for the dict)\n",
    "    {\n",
    "        \"call_both_parallel\": \"run_parallel_agents\", # Map decision to the parallel execution node\n",
    "        \"call_insights_only\": \"run_insights_agent\",  # Map decision to the insights agent node\n",
    "        \"call_summary_only\": \"run_summary_agent\",    # Map decision to the summary agent node\n",
    "        \"end_workflow\": END                          # Map decision to the END state\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ebdc0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7aaf4751ddc0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After each agent completes, return to the supervisor for the next intelligent decision\n",
    "workflow.add_edge(\"run_summary_agent\", \"intelligent_supervisor\")\n",
    "workflow.add_edge(\"run_insights_agent\", \"intelligent_supervisor\")\n",
    "workflow.add_edge(\"run_parallel_agents\", \"intelligent_supervisor\") # Add this edge for parallel execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a0d9a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c3f2314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Intelligent Meeting Processing Workflow\n",
      "üì¶ Stored data of type 'document_content' with ID: document_content_1753356097298_475\n",
      "\n",
      "--- Workflow Iteration: 1 ---\n",
      "\n",
      "========================================\n",
      "STEP: increment_iteration\n",
      "STATE: {'document_content_id': 'document_content_1753356097298_475', 'summary_status': 'pending', 'insights_status': 'pending', 'summary_id': None, 'insights_id': None, 'iteration': 1, 'error_message': None, 'current_reasoning': '', 'next': ''}\n",
      "\n",
      "üß† AI Supervisor thinking... (Iteration: 1)\n",
      "state: {'document_content_id': 'document_content_1753356097298_475', 'summary_status': 'pending', 'insights_status': 'pending', 'summary_id': None, 'insights_id': None, 'iteration': 1, 'error_message': None, 'current_reasoning': '', 'next': ''}\n",
      "üí≠ AI Reasoning: Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.\n",
      "‚ö° Decision: call_both_parallel (confidence: 0.95)\n",
      "goto: call_both_parallel\n",
      "\n",
      "========================================\n",
      "STEP: intelligent_supervisor\n",
      "STATE: {'current_reasoning': 'Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.', 'next': 'call_both_parallel'}\n",
      "\n",
      "---RUNNING BOTH REFACTORED AGENTS IN PARALLEL---\n",
      "\n",
      "ü§ñ Modern Agentic Summary Node Called...\n",
      "\n",
      "üí° Specialist Insights Node Called...\n",
      " retrievel data of type 'document_content' with ID: document_content_1753356097298_475\n",
      "üß† Agent is thinking and generating the summary...\n",
      " retrievel data of type 'document_content' with ID: document_content_1753356097298_475\n",
      "üß† Specialist is analyzing and extracting insights...\n",
      "‚úÖ Insights Specialist: Extracted insights successfully. **Key Themes**\n",
      "===============\n",
      "\n",
      "* **Strategic Resource Allocation**: The meeting minutes hint at potential misalignment on departmental priorities, with discussions around budget reviews and resource allocation for various projects.\n",
      "\n",
      "**Critical Decisions & Implications**\n",
      "=====================================\n",
      "\n",
      "* **Decision: Project Phoenix Server Deployment**: Implication: This marks a significant milestone in the project's progress, indicating a commitment to investing in new technologies and potentially paving the way for future innovations.\n",
      "* **Decision: Summer Sale Launch**: Implication: This launch signals a strategic focus on driving revenue through targeted marketing campaigns, which may have implications for resource allocation and prioritization across departments.\n",
      "\n",
      "**Actionable Insights**\n",
      "=====================\n",
      "\n",
      "* **Insight: Departmental Priority Alignment**: The meeting highlights the need for a cross-departmental priority-setting workshop to ensure alignment on strategic objectives and resource allocation.\n",
      "* **Insight: Technology Investment Strategy**: The deployment of the Project Phoenix server and the refinement of the BERT chatbot suggest a strategic focus on technology investments. The leadership team should consider the long-term implications of these investments on the company's overall direction and resource allocation.\n",
      "üì¶ Stored data of type 'insights_output' with ID: insights_output_1753356101244_335\n",
      "\n",
      "üõ†Ô∏è Action Item Tool Called...\n",
      "üì¶ Stored data of type 'action_items' with ID: action_items_1753356149219_114\n",
      "‚úÖ Action items extracted and stored successfully.\n",
      "‚úÖ Summary Agent: Generated summary successfully.::: Confirmation: Successfully stored 2 action items with ID action_items_1753356149219_114\n",
      "‚úÖ Summary node captured Action Item ID: action_items_1753356149219_114\n",
      "üì¶ Stored data of type 'summary_output' with ID: summary_output_1753356149225_365\n",
      "\n",
      "========================================\n",
      "STEP: run_parallel_agents\n",
      "STATE: {'summary_status': 'success', 'summary_id': 'summary_output_1753356149225_365', 'error_message': '', 'insights_status': 'success', 'insights_id': 'insights_output_1753356101244_335'}\n",
      "\n",
      "--- Workflow Iteration: 2 ---\n",
      "\n",
      "========================================\n",
      "STEP: increment_iteration\n",
      "STATE: {'document_content_id': 'document_content_1753356097298_475', 'summary_status': 'success', 'insights_status': 'success', 'summary_id': 'summary_output_1753356149225_365', 'insights_id': 'insights_output_1753356101244_335', 'iteration': 2, 'error_message': '', 'current_reasoning': 'Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.', 'next': 'call_both_parallel'}\n",
      "\n",
      "üß† AI Supervisor thinking... (Iteration: 2)\n",
      "state: {'document_content_id': 'document_content_1753356097298_475', 'summary_status': 'success', 'insights_status': 'success', 'summary_id': 'summary_output_1753356149225_365', 'insights_id': 'insights_output_1753356101244_335', 'iteration': 2, 'error_message': '', 'current_reasoning': 'Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.', 'next': 'call_both_parallel'}\n",
      "üí≠ AI Reasoning: Both summary and insights have been successfully obtained, so the workflow should be ended.\n",
      "‚ö° Decision: end_workflow (confidence: 1.00)\n",
      "goto: __end__\n",
      "\n",
      "========================================\n",
      "STEP: intelligent_supervisor\n",
      "STATE: {'current_reasoning': 'Both summary and insights have been successfully obtained, so the workflow should be ended.', 'next': 'end_workflow'}\n",
      "\n",
      "üéØ Workflow completed with AI supervision!\n",
      "\n",
      "\n",
      "--- FINAL RESULTS ---\n",
      "\n",
      "‚úÖ Final State: {'document_content_id': 'document_content_1753356097298_475', 'summary_status': 'success', 'insights_status': 'success', 'summary_id': 'summary_output_1753356149225_365', 'insights_id': 'insights_output_1753356101244_335', 'iteration': 2, 'error_message': '', 'current_reasoning': 'Both summary and insights have been successfully obtained, so the workflow should be ended.', 'next': 'end_workflow'}\n",
      " retrievel data of type 'summary_output' with ID: summary_output_1753356149225_365\n",
      " retrievel data of type 'insights_output' with ID: insights_output_1753356101244_335\n",
      "\n",
      "‚úÖ Final Summary:\n",
      "Confirmation: Successfully stored 2 action items with ID action_items_1753356149219_114\n",
      "\n",
      "‚úÖ Final Insights:\n",
      "**Key Themes**\n",
      "===============\n",
      "\n",
      "* **Strategic Resource Allocation**: The meeting minutes hint at potential misalignment on departmental priorities, with discussions around budget reviews and resource allocation for various projects.\n",
      "\n",
      "**Critical Decisions & Implications**\n",
      "=====================================\n",
      "\n",
      "* **Decision: Project Phoenix Server Deployment**: Implication: This marks a significant milestone in the project's progress, indicating a commitment to investing in new technologies and potentially paving the way for future innovations.\n",
      "* **Decision: Summer Sale Launch**: Implication: This launch signals a strategic focus on driving revenue through targeted marketing campaigns, which may have implications for resource allocation and prioritization across departments.\n",
      "\n",
      "**Actionable Insights**\n",
      "=====================\n",
      "\n",
      "* **Insight: Departmental Priority Alignment**: The meeting highlights the need for a cross-departmental priority-setting workshop to ensure alignment on strategic objectives and resource allocation.\n",
      "* **Insight: Technology Investment Strategy**: The deployment of the Project Phoenix server and the refinement of the BERT chatbot suggest a strategic focus on technology investments. The leadership team should consider the long-term implications of these investments on the company's overall direction and resource allocation.\n",
      "\n",
      "‚úÖ Extracted Action Items:\n"
     ]
    }
   ],
   "source": [
    "# --- Test the intelligent workflow ---\n",
    "print(\"üöÄ Starting Intelligent Meeting Processing Workflow\")\n",
    "\n",
    "    # A. Store the initial document and get its ID\n",
    "document_text = \"Meeting Minutes - July 22, 2025\\nAttendees: Alice, Bob, Charlie\\n1. Project Phoenix: Bob confirmed the server is deployed. Action Item: Charlie to schedule a budget review by Friday.\\n2. Marketing: The 'Summer Sale' will launch on August 1st. Action Item: AI team to refine the BERT chatbot for user intent by July 28th.\"\n",
    "doc_id = DataStorage.store('document_content', document_text)\n",
    "\n",
    "    # B. Define the initial state using the ID\n",
    "initial_state = {\n",
    "        \"document_content_id\": doc_id,\n",
    "        \"summary_status\": \"pending\",  \n",
    "        \"insights_status\": \"pending\", \n",
    "        \"summary_id\": None,\n",
    "        \"insights_id\": None,\n",
    "        \"action_items_id\": None,\n",
    "        \"iteration\": 0,\n",
    "        \"error_message\": None,\n",
    "        \"current_reasoning\": \"\",\n",
    "        \"next\": \"\"\n",
    "    }\n",
    "\n",
    "# In your main execution script:\n",
    "\n",
    "# C. Run the workflow and capture the final state\n",
    "final_state = {}\n",
    "for step in app.stream(initial_state, {\"recursion_limit\": 10}):\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    step_name = list(step.keys())[0]\n",
    "    print(f\"STEP: {step_name}\")\n",
    "    print(f\"STATE: {step[step_name]}\")\n",
    "    # Instead of overwriting, UPDATE the dictionary to build the complete final state\n",
    "    final_state.update(step[step_name])\n",
    "\n",
    "    # C. Run the workflow and capture the final state\n",
    "# final_state = {}\n",
    "# for step in app.stream(initial_state, {\"recursion_limit\": 10}):\n",
    "#     print(\"\\n\" + \"=\"*40)\n",
    "#     print(f\"STEP: {list(step.keys())[0]}\")\n",
    "#     print(f\"STATE: {step[list(step.keys())[0]]}\")\n",
    "#     final_state = step[list(step.keys())[0]]\n",
    "\n",
    "print(\"\\nüéØ Workflow completed with AI supervision!\")\n",
    "\n",
    "    # D. Retrieve and display the final results from DataStorage\n",
    "# D. Retrieve and display the final results from DataStorage\n",
    "print(\"\\n\\n--- FINAL RESULTS ---\")\n",
    "\n",
    "print(\"\\n‚úÖ Final State:\",final_state)\n",
    "\n",
    "# Corrected to use 'summary_id' and 'insights_id'\n",
    "summary = DataStorage.retrieve('summary_output', final_state.get('summary_id', ''))\n",
    "insights = DataStorage.retrieve('insights_output', final_state.get('insights_id', ''))\n",
    "\n",
    "print(\"\\n‚úÖ Final Summary:\")\n",
    "print(summary or \"Not generated.\")\n",
    "\n",
    "print(\"\\n‚úÖ Final Insights:\")\n",
    "print(insights or \"Not generated.\")\n",
    "\n",
    "print(\"\\n‚úÖ Extracted Action Items:\")\n",
    "\n",
    "for item_id in final_state.get('action_items_ids', []):\n",
    "    action_items = DataStorage.retrieve('action_items', item_id)\n",
    "    if action_items:\n",
    "        # Assuming action_items is a list of Pydantic models or dicts\n",
    "        for i, item in enumerate(action_items):\n",
    "            owner = getattr(item, 'owner', 'N/A')\n",
    "            task = getattr(item, 'task', 'N/A')\n",
    "            deadline = getattr(item, 'deadline', 'N/A')\n",
    "            print(f\"  - Task: {task}, Owner: {owner}, Deadline: {deadline}\")\n",
    "    else:\n",
    "        print(\"  - Could not retrieve action items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4f2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987cee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1c43304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Intelligent Meeting Processing Workflow\n",
      "üì¶ Stored data of type 'document_content' with ID: document_content_1753356176890_893\n",
      "\n",
      "--- Workflow Iteration: 1 ---\n",
      "\n",
      "========================================\n",
      "STEP: increment_iteration\n",
      "========================================\n",
      "STATE UPDATE: {'document_content_id': 'document_content_1753356176890_893', 'summary_status': 'pending', 'insights_status': 'pending', 'summary_id': None, 'insights_id': None, 'iteration': 1, 'error_message': '', 'current_reasoning': '', 'next': ''}\n",
      "\n",
      "üß† AI Supervisor thinking... (Iteration: 1)\n",
      "state: {'document_content_id': 'document_content_1753356176890_893', 'summary_status': 'pending', 'insights_status': 'pending', 'summary_id': None, 'insights_id': None, 'iteration': 1, 'error_message': '', 'current_reasoning': '', 'next': ''}\n",
      "üí≠ AI Reasoning: Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.\n",
      "‚ö° Decision: call_both_parallel (confidence: 0.95)\n",
      "goto: call_both_parallel\n",
      "\n",
      "========================================\n",
      "STEP: intelligent_supervisor\n",
      "========================================\n",
      "STATE UPDATE: {'current_reasoning': 'Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.', 'next': 'call_both_parallel'}\n",
      "\n",
      "---RUNNING BOTH REFACTORED AGENTS IN PARALLEL---\n",
      "\n",
      "ü§ñ Modern Agentic Summary Node Called...\n",
      "\n",
      "üí° Specialist Insights Node Called...\n",
      " retrievel data of type 'document_content' with ID: document_content_1753356176890_893\n",
      "üß† Specialist is analyzing and extracting insights...\n",
      " retrievel data of type 'document_content' with ID: document_content_1753356176890_893\n",
      "üß† Agent is thinking and generating the summary...\n",
      "‚úÖ Insights Specialist: Extracted insights successfully. **Key Themes**\n",
      "===============\n",
      "\n",
      "* **Resource Allocation and Prioritization**: The meeting minutes hint at potential misalignment on departmental priorities, with discussions around budget reviews and resource allocation for various projects.\n",
      "\n",
      "**Critical Decisions & Implications**\n",
      "=====================================\n",
      "\n",
      "* **Decision: Phoenix Project Server Deployment**: The server deployment marks a significant milestone in the project's progress, implying a continued commitment to innovation and potentially paving the way for future growth opportunities.\n",
      "* **Decision: Summer Sale Launch**: The launch of the Summer Sale campaign on August 1st signals a strategic focus on driving revenue and customer engagement, potentially setting the tone for future marketing initiatives.\n",
      "\n",
      "**Actionable Insights**\n",
      "=====================\n",
      "\n",
      "* **Insight: Departmental Priority Alignment**: The meeting highlights the need for cross-departmental priority-setting to ensure effective resource allocation and minimize potential misalignment.\n",
      "* **Insight: Innovation and Growth**: The progress on Project Phoenix and the launch of the Summer Sale campaign suggest a strategic emphasis on driving growth and innovation, which may require continued investment and resource commitment.\n",
      "üì¶ Stored data of type 'insights_output' with ID: insights_output_1753356184010_592\n",
      "\n",
      "üõ†Ô∏è Action Item Tool Called...\n",
      "üì¶ Stored data of type 'action_items' with ID: action_items_1753356192581_198\n",
      "‚úÖ Action items extracted and stored successfully.\n",
      "‚úÖ Summary Agent: Generated summary successfully.::: Confirmation: Successfully stored 2 action items with ID action_items_1753356192581_198\n",
      "‚úÖ Summary node captured Action Item ID: action_items_1753356192581_198\n",
      "üì¶ Stored data of type 'summary_output' with ID: summary_output_1753356192587_186\n",
      "\n",
      "========================================\n",
      "STEP: run_parallel_agents\n",
      "========================================\n",
      "STATE UPDATE: {'summary_status': 'success', 'summary_id': 'summary_output_1753356192587_186', 'error_message': '', 'insights_status': 'success', 'insights_id': 'insights_output_1753356184010_592'}\n",
      "\n",
      "--- Workflow Iteration: 2 ---\n",
      "\n",
      "========================================\n",
      "STEP: increment_iteration\n",
      "========================================\n",
      "STATE UPDATE: {'document_content_id': 'document_content_1753356176890_893', 'summary_status': 'success', 'insights_status': 'success', 'summary_id': 'summary_output_1753356192587_186', 'insights_id': 'insights_output_1753356184010_592', 'iteration': 2, 'error_message': '', 'current_reasoning': 'Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.', 'next': 'call_both_parallel'}\n",
      "\n",
      "üß† AI Supervisor thinking... (Iteration: 2)\n",
      "state: {'document_content_id': 'document_content_1753356176890_893', 'summary_status': 'success', 'insights_status': 'success', 'summary_id': 'summary_output_1753356192587_186', 'insights_id': 'insights_output_1753356184010_592', 'iteration': 2, 'error_message': '', 'current_reasoning': 'Starting with parallel execution in the first iteration is efficient as both tasks are pending and there are no errors.', 'next': 'call_both_parallel'}\n",
      "üí≠ AI Reasoning: Both the summary and insights have been successfully obtained, so the workflow should be ended.\n",
      "‚ö° Decision: end_workflow (confidence: 1.00)\n",
      "goto: __end__\n",
      "\n",
      "========================================\n",
      "STEP: intelligent_supervisor\n",
      "========================================\n",
      "STATE UPDATE: {'current_reasoning': 'Both the summary and insights have been successfully obtained, so the workflow should be ended.', 'next': 'end_workflow'}\n",
      "\n",
      "\n",
      "üéØ Workflow completed!\n",
      " retrievel data of type 'summary_output' with ID: summary_output_1753356192587_186\n",
      " retrievel data of type 'insights_output' with ID: insights_output_1753356184010_592\n",
      "\n",
      "‚úÖ Final Summary:\n",
      " Confirmation: Successfully stored 2 action items with ID action_items_1753356192581_198\n",
      "\n",
      "‚úÖ Final Insights:\n",
      " **Key Themes**\n",
      "===============\n",
      "\n",
      "* **Resource Allocation and Prioritization**: The meeting minutes hint at potential misalignment on departmental priorities, with discussions around budget reviews and resource allocation for various projects.\n",
      "\n",
      "**Critical Decisions & Implications**\n",
      "=====================================\n",
      "\n",
      "* **Decision: Phoenix Project Server Deployment**: The server deployment marks a significant milestone in the project's progress, implying a continued commitment to innovation and potentially paving the way for future growth opportunities.\n",
      "* **Decision: Summer Sale Launch**: The launch of the Summer Sale campaign on August 1st signals a strategic focus on driving revenue and customer engagement, potentially setting the tone for future marketing initiatives.\n",
      "\n",
      "**Actionable Insights**\n",
      "=====================\n",
      "\n",
      "* **Insight: Departmental Priority Alignment**: The meeting highlights the need for cross-departmental priority-setting to ensure effective resource allocation and minimize potential misalignment.\n",
      "* **Insight: Innovation and Growth**: The progress on Project Phoenix and the launch of the Summer Sale campaign suggest a strategic emphasis on driving growth and innovation, which may require continued investment and resource commitment.\n",
      "\n",
      "‚úÖ Extracted Action Items:\n",
      "  - No action items were processed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"increment_iteration\", increment_iteration)\n",
    "workflow.add_node(\"intelligent_supervisor\", intelligent_supervisor)\n",
    "workflow.add_node(\"run_summary_agent\", run_summary_agent)\n",
    "workflow.add_node(\"run_insights_agent\", run_insights_agent)\n",
    "workflow.add_node(\"run_parallel_agents\", run_both_parallel_agents)\n",
    "\n",
    "# Define the edges\n",
    "workflow.set_entry_point(\"increment_iteration\")\n",
    "workflow.add_edge(\"increment_iteration\", \"intelligent_supervisor\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"intelligent_supervisor\", route_supervisor_decision,\n",
    "    {\"call_both_parallel\": \"run_parallel_agents\", \"call_insights_only\": \"run_insights_agent\",\n",
    "        \"call_summary_only\": \"run_summary_agent\", \"end_workflow\": END}\n",
    ")\n",
    "workflow.add_edge(\"run_summary_agent\", \"increment_iteration\")\n",
    "workflow.add_edge(\"run_insights_agent\", \"increment_iteration\")\n",
    "workflow.add_edge(\"run_parallel_agents\", \"increment_iteration\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"üöÄ Starting Intelligent Meeting Processing Workflow\")\n",
    "document_text = \"Meeting Minutes - July 23, 2025\\nAttendees: Alice, Bob, Charlie\\n1. Project Phoenix: Bob confirmed the server is deployed. Action Item: Charlie to schedule a budget review by Friday.\\n2. Marketing: The 'Summer Sale' will launch on August 1st. Action Item: AI team to refine the BERT chatbot for user intent by July 28th.\"\n",
    "doc_id = DataStorage.store('document_content', document_text)\n",
    "\n",
    "initial_state = {\n",
    "    \"document_content_id\": doc_id,\n",
    "    \"summary_status\": \"pending\",\n",
    "    \"insights_status\": \"pending\",\n",
    "    \"summary_id\": None,\n",
    "    \"insights_id\": None,\n",
    "    \"action_items_ids\": [],\n",
    "    \"iteration\": 0,\n",
    "    \"error_message\": \"\",\n",
    "    \"current_reasoning\": \"\",\n",
    "    \"next\": \"\"\n",
    "}\n",
    "\n",
    "final_state = {}\n",
    "for step in app.stream(initial_state, {\"recursion_limit\": 15}):\n",
    "    node_name = list(step.keys())[0]\n",
    "    state_update = step[node_name]\n",
    "    print(\"\\n\" + \"=\"*40 + f\"\\nSTEP: {node_name}\\n\" + \"=\"*40)\n",
    "    if isinstance(state_update, dict):\n",
    "        final_state.update(state_update)\n",
    "    print(f\"STATE UPDATE: {state_update}\")\n",
    "\n",
    "print(\"\\n\\nüéØ Workflow completed!\")\n",
    "\n",
    "# FIX: Corrected the data_type for retrieving the final results.\n",
    "summary = DataStorage.retrieve('summary_output', final_state.get('summary_id', ''))\n",
    "insights = DataStorage.retrieve('insights_output', final_state.get('insights_id', ''))\n",
    "print(\"\\n‚úÖ Final Summary:\\n\", summary or \"Not generated.\")\n",
    "print(\"\\n‚úÖ Final Insights:\\n\", insights or \"Not generated.\")\n",
    "\n",
    "print(\"\\n‚úÖ Extracted Action Items:\")\n",
    "action_item_ids = final_state.get('action_items_ids', [])\n",
    "if not action_item_ids:\n",
    "    print(\"  - No action items were processed.\")\n",
    "else:\n",
    "    for item_id in action_item_ids:\n",
    "        action_items = DataStorage.retrieve('action_items', item_id)\n",
    "        if action_items:\n",
    "            for i, item in enumerate(action_items):\n",
    "                print(f\"  - Task: {item.task}, Owner: {item.owner}, Deadline: {item.deadline}\")\n",
    "        else:\n",
    "            print(f\"  - Could not retrieve action items for ID: {item_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d661ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import re\n",
    "# import time\n",
    "# from typing import TypedDict, Literal, List, Optional, Dict, Any\n",
    "\n",
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# from langchain.agents import create_react_agent, AgentExecutor\n",
    "# from langchain_core.tools import tool\n",
    "# from langchain_groq import ChatGroq\n",
    "# from langgraph.graph import StateGraph, END\n",
    "\n",
    "# # --- 1. Data Storage and State Definition ---\n",
    "\n",
    "# class DataStorage:\n",
    "#     \"\"\"Simulates a database. In production, replace with Redis, a DB, etc.\"\"\"\n",
    "#     _storage = {\n",
    "#         'document_content': {},\n",
    "#         'summary_output': {},\n",
    "#         'insights_output': {},\n",
    "#         'action_items': {}\n",
    "#     }\n",
    "    \n",
    "#     @classmethod\n",
    "#     def store(cls, data_type: str, data: any) -> str:\n",
    "#         uid = f\"{data_type}_{int(time.time() * 1000)}_{random.randint(100, 999)}\"\n",
    "#         cls._storage[data_type][uid] = data\n",
    "#         print(f\"üì¶ Stored '{data_type}' with ID: {uid}\")\n",
    "#         return uid\n",
    "    \n",
    "#     @classmethod\n",
    "#     def retrieve(cls, data_type: str, uid: str) -> any:\n",
    "#         print(f\"üì• Retrieving '{data_type}' with ID: {uid}\")\n",
    "#         return cls._storage[data_type].get(uid)\n",
    "\n",
    "# class GraphState(TypedDict):\n",
    "#     \"\"\"State using the correct ID field names for scalability.\"\"\"\n",
    "#     document_content_id: str\n",
    "#     summary_status: str\n",
    "#     insights_status: str\n",
    "#     summary_id: Optional[str]\n",
    "#     insights_id: Optional[str]\n",
    "#     action_items_ids: List[str]\n",
    "#     iteration: int\n",
    "#     error_message: str\n",
    "#     current_reasoning: str\n",
    "#     next: str\n",
    "\n",
    "# # --- 2. Tool for Action Item Extraction ---\n",
    "\n",
    "# class ActionItem(BaseModel):\n",
    "#     task: str = Field(description=\"The specific action or task to be completed.\")\n",
    "#     owner: str = Field(description=\"The person or team responsible for the task.\")\n",
    "#     deadline: str = Field(description=\"The due date for the task, e.g., 'EOW', '2024-08-15'.\")\n",
    "\n",
    "# @tool\n",
    "# def extract_and_store_action_items(document_content: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Identifies action items in a document, structures them,\n",
    "#     stores them, and returns a confirmation with the storage ID.\n",
    "#     \"\"\"\n",
    "#     print(\"\\nüõ†Ô∏è Action Item Tool Called...\")\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", \"You are an expert at extracting structured data. Identify all action items from the provided text. For each action item, extract the task description, the owner, and the deadline. Use 'N/A' if a detail is missing.\"),\n",
    "#         (\"human\", \"Please extract all action items from this document:\\n\\n---\\n\\n{document}\")\n",
    "#     ])\n",
    "#     llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
    "#     extractor = prompt | llm.with_structured_output(schema=List[ActionItem])\n",
    "    \n",
    "#     try:\n",
    "#         action_items_list = extractor.invoke({\"document\": document_content})\n",
    "#         if not action_items_list:\n",
    "#             return \"No action items were found in the document.\"\n",
    "#         storage_id = DataStorage.store('action_items', action_items_list)\n",
    "#         print(f\"‚úÖ Action items stored successfully.\")\n",
    "#         return f\"Successfully extracted and stored {len(action_items_list)} action items with ID: {storage_id}\"\n",
    "#     except Exception as e:\n",
    "#         return f\"An error occurred while trying to extract action items: {e}\"\n",
    "\n",
    "# # --- 3. Refactored Agent Nodes (with Corrected Prompts) ---\n",
    "\n",
    "# def run_summary_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"Refactored summary agent using the correct ChatPromptTemplate structure.\"\"\"\n",
    "#     print(\"\\nü§ñ Refactored Summary Agent Called...\")\n",
    "    \n",
    "#     # FIX: Using ChatPromptTemplate and providing explicit JSON output instructions.\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", \"\"\"\n",
    "#         You are an expert Meeting Summarization Agent. Your sole mission is to create a concise, structured, and insightful summary from the provided meeting minutes.\n",
    "#         Prioritize key decisions, major topics, and outcomes.\n",
    "#         If you identify any specific tasks assigned to people (action items), you MUST use the 'extract_and_store_action_items' tool to process them.\n",
    "#         Do not list the action items in your final answer; just mention that they were processed separately.\n",
    "\n",
    "#         You have access to the following tools:\n",
    "#         {tools}\n",
    "\n",
    "#         To use a tool, respond with a JSON blob with 'action' and 'action_input' keys.\n",
    "#         When you have your final summary, you MUST respond with a JSON blob with a single 'answer' key.\n",
    "#         \"\"\"),\n",
    "#         (\"user\", \"{input}\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#     ])\n",
    "    \n",
    "#     llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
    "#     tools = [extract_and_store_action_items]\n",
    "#     agent = create_react_agent(llm, tools, prompt=prompt)\n",
    "#     agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "#     try:\n",
    "#         document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "#         if not document_content:\n",
    "#             raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "\n",
    "#         agent_input = {\n",
    "#             \"input\": f\"Please generate a summary for the following meeting minutes:\\n\\n---\\n\\n{document_content}\",\n",
    "#             # Pass the document content to the tool as well, as it needs it directly\n",
    "#             \"document_content\": document_content \n",
    "#         }\n",
    "#         result = agent_executor.invoke(agent_input)\n",
    "        \n",
    "#         summary_id = DataStorage.store('summary_output', result['output'])\n",
    "        \n",
    "#         new_action_item_ids = state.get('action_items_ids', [])\n",
    "#         if 'intermediate_steps' in result:\n",
    "#             for _, tool_output in result['intermediate_steps']:\n",
    "#                 match = re.search(r\"ID: (action_items_\\d+_\\d+)\", tool_output)\n",
    "#                 if match:\n",
    "#                     new_action_item_ids.append(match.group(1))\n",
    "\n",
    "#         return {\n",
    "#             \"summary_status\": \"success\",\n",
    "#             \"summary_id\": summary_id,\n",
    "#             \"action_items_ids\": new_action_item_ids,\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in Summary Agent: {e}\")\n",
    "#         return {\n",
    "#             \"summary_status\": \"failed\",\n",
    "#             \"error_message\": f\"Summary Agent Error: {str(e)}\"\n",
    "#         }\n",
    "\n",
    "# def run_insights_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"Refactored insights agent using the correct ChatPromptTemplate structure.\"\"\"\n",
    "#     print(\"\\nü§ñ Refactored Insights Agent Called...\")\n",
    "    \n",
    "#     # FIX: Using ChatPromptTemplate and providing explicit JSON output instructions.\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", \"\"\"\n",
    "#         You are an expert Meeting Insights Agent. Your mission is to extract not just facts, but the underlying meaning, implications of decisions, and strategic insights from the meeting minutes.\n",
    "#         You are focused on the 'why' and 'so what', not just the 'what'. You do not need to process action items.\n",
    "\n",
    "#         Since you don't need to use tools for this task, think through the user's request and then provide your final answer.\n",
    "#         When you have your final answer, you MUST respond with a JSON blob with a single 'answer' key.\n",
    "#         \"\"\"),\n",
    "#         (\"user\", \"{input}\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#     ])\n",
    "    \n",
    "#     llm = ChatGroq(temperature=0.1, model=\"llama3-70b-8192\")\n",
    "#     tools = [] \n",
    "#     agent = create_react_agent(llm, tools, prompt=prompt)\n",
    "#     agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "#     try:\n",
    "#         document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "#         if not document_content:\n",
    "#             raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "\n",
    "#         agent_input = {\n",
    "#             \"input\": f\"Please extract key insights from these meeting minutes:\\n\\n---\\n\\n{document_content}\"\n",
    "#         }\n",
    "#         result = agent_executor.invoke(agent_input)\n",
    "        \n",
    "#         insights_id = DataStorage.store('insights_output', result['output'])\n",
    "        \n",
    "#         return {\n",
    "#             \"insights_status\": \"success\",\n",
    "#             \"insights_id\": insights_id,\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in Insights Agent: {e}\")\n",
    "#         return {\n",
    "#             \"insights_status\": \"failed\",\n",
    "#             \"error_message\": f\"Insights Agent Error: {str(e)}\"\n",
    "#         }\n",
    "\n",
    "# def run_both_parallel_agents(state: GraphState) -> dict:\n",
    "#     \"\"\"Runs the refactored summary and insights agents in parallel.\"\"\"\n",
    "#     print(\"\\n---RUNNING BOTH REFACTORED AGENTS IN PARALLEL---\")\n",
    "#     # Note: LangGraph's parallel execution might not show verbose agent logs clearly.\n",
    "#     # Running agents sequentially is better for debugging agent thoughts.\n",
    "#     return {**run_summary_agent(state), **run_insights_agent(state)}\n",
    "\n",
    "# # --- 4. Supervisor and Routing Logic ---\n",
    "\n",
    "# class SupervisorDecision(BaseModel):\n",
    "#     \"\"\"AI Supervisor's decision with reasoning.\"\"\"\n",
    "#     next_action: Literal[\"call_both_parallel\", \"call_summary_only\", \"call_insights_only\", \"end_workflow\"]\n",
    "#     reasoning: str\n",
    "\n",
    "# def intelligent_supervisor(state: GraphState) -> Dict[str, Any]:\n",
    "#     \"\"\"Smart supervisor with the heuristic-based prompt.\"\"\"\n",
    "#     print(f\"\\nüß† AI Supervisor thinking... (Iteration: {state['iteration']})\")\n",
    "    \n",
    "#     system_prompt = \"\"\"\n",
    "#     You are an intelligent workflow supervisor using ReAct (Reasoning + Acting) methodology. \n",
    "#     Your mission is to ensure we successfully get a meeting summary and key insights stored efficiently.\n",
    "#     A task is 'successful' if its status is 'success' AND its ID exists. A task has 'failed' if its status is 'failed'.\n",
    "#     Based on your observation of the state, decide the smartest next action.\n",
    "\n",
    "#     ## CURRENT WORKFLOW STATE:\n",
    "#     - Summary Status: {summary_status} (summary_id: {summary_id})\n",
    "#     - Insights Status: {insights_status} (insights_id: {insights_id})\n",
    "#     - Iteration: {iteration}\n",
    "#     - Last Error: {error_msg}\n",
    "\n",
    "#     ## AVAILABLE ACTIONS:\n",
    "#     - call_both_parallel, call_summary_only, call_insights_only, end_workflow\n",
    "\n",
    "#     ## INTELLIGENT DECISION GUIDELINES:\n",
    "#     - Iteration 1: Usually start with parallel execution for efficiency.\n",
    "#     - One success, one failure: Target retry on the failed agent only.\n",
    "#     - Both failed in early iterations: Likely a temporary issue, retry both.\n",
    "#     - Both successful: Mission accomplished! Time to end the workflow.\n",
    "#     \"\"\"\n",
    "#     formatted_prompt = system_prompt.format(\n",
    "#         summary_status=state['summary_status'],\n",
    "#         summary_id=f\"'{state['summary_id']}'\" if state.get('summary_id') else \"None\",\n",
    "#         insights_status=state['insights_status'],\n",
    "#         insights_id=f\"'{state['insights_id']}'\" if state.get('insights_id') else \"None\",\n",
    "#         iteration=state['iteration'],\n",
    "#         error_msg=state.get('error_message') or \"None\"\n",
    "#     )\n",
    "    \n",
    "#     llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
    "#     decision_chain = ChatPromptTemplate.from_messages(\n",
    "#         [(\"system\", formatted_prompt), (\"human\", \"Analyze the state and decide the next action.\")]\n",
    "#     ) | llm.with_structured_output(SupervisorDecision)\n",
    "    \n",
    "#     try:\n",
    "#         decision = decision_chain.invoke({})\n",
    "#     except Exception as e:\n",
    "#         return {\"next\": \"end_workflow\", \"current_reasoning\": f\"Supervisor LLM failed: {e}\"}\n",
    "\n",
    "#     print(f\"üí≠ AI Reasoning: {decision.reasoning}\\n‚ö° Decision: {decision.next_action}\")\n",
    "    \n",
    "#     if state['summary_status'] == 'success' and state['insights_status'] == 'success':\n",
    "#         return {\"next\": \"end_workflow\"}\n",
    "\n",
    "#     return {\"current_reasoning\": decision.reasoning, \"next\": decision.next_action}\n",
    "\n",
    "# def route_supervisor_decision(state: GraphState) -> str:\n",
    "#     return state['next']\n",
    "\n",
    "# def increment_iteration(state: GraphState) -> dict:\n",
    "#     return {\"iteration\": state.get('iteration', 0) + 1}\n",
    "\n",
    "# # --- 5. Graph Definition and Execution ---\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Define the graph\n",
    "#     workflow = StateGraph(GraphState)\n",
    "#     workflow.add_node(\"increment_iteration\", increment_iteration)\n",
    "#     workflow.add_node(\"intelligent_supervisor\", intelligent_supervisor)\n",
    "#     workflow.add_node(\"run_summary_agent\", run_summary_agent)\n",
    "#     workflow.add_node(\"run_insights_agent\", run_insights_agent)\n",
    "#     workflow.add_node(\"run_parallel_agents\", run_both_parallel_agents)\n",
    "\n",
    "#     # Define the edges\n",
    "#     workflow.set_entry_point(\"increment_iteration\")\n",
    "#     workflow.add_edge(\"increment_iteration\", \"intelligent_supervisor\")\n",
    "#     workflow.add_conditional_edges(\n",
    "#         \"intelligent_supervisor\", route_supervisor_decision,\n",
    "#         {\"call_both_parallel\": \"run_parallel_agents\", \"call_insights_only\": \"run_insights_agent\",\n",
    "#          \"call_summary_only\": \"run_summary_agent\", \"end_workflow\": END}\n",
    "#     )\n",
    "#     workflow.add_edge(\"run_summary_agent\", \"increment_iteration\")\n",
    "#     workflow.add_edge(\"run_insights_agent\", \"increment_iteration\")\n",
    "#     workflow.add_edge(\"run_parallel_agents\", \"increment_iteration\")\n",
    "    \n",
    "#     app = workflow.compile()\n",
    "\n",
    "#     print(\"üöÄ Starting Intelligent Meeting Processing Workflow\")\n",
    "#     document_text = \"Meeting Minutes - July 23, 2025\\nAttendees: Alice, Bob, Charlie\\n1. Project Phoenix: Bob confirmed the server is deployed. Action Item: Charlie to schedule a budget review by Friday.\\n2. Marketing: The 'Summer Sale' will launch on August 1st. Action Item: AI team to refine the BERT chatbot for user intent by July 28th.\"\n",
    "#     doc_id = DataStorage.store('document_content', document_text)\n",
    "\n",
    "#     initial_state = {\n",
    "#         \"document_content_id\": doc_id,\n",
    "#         \"summary_status\": \"pending\",\n",
    "#         \"insights_status\": \"pending\",\n",
    "#         \"summary_id\": None,\n",
    "#         \"insights_id\": None,\n",
    "#         \"action_items_ids\": [],\n",
    "#         \"iteration\": 0,\n",
    "#         \"error_message\": \"\",\n",
    "#         \"current_reasoning\": \"\",\n",
    "#         \"next\": \"\"\n",
    "#     }\n",
    "\n",
    "#     final_state = {}\n",
    "#     for step in app.stream(initial_state, {\"recursion_limit\": 15}):\n",
    "#         node_name = list(step.keys())[0]\n",
    "#         state_update = step[node_name]\n",
    "#         print(\"\\n\" + \"=\"*40 + f\"\\nSTEP: {node_name}\\n\" + \"=\"*40)\n",
    "#         if isinstance(state_update, dict):\n",
    "#             final_state.update(state_update)\n",
    "#         print(f\"STATE UPDATE: {state_update}\")\n",
    "\n",
    "#     print(\"\\n\\nüéØ Workflow completed!\")\n",
    "#     summary = DataStorage.retrieve('summary_output', final_state.get('summary_id', ''))\n",
    "#     insights = DataStorage.retrieve('insights_output', final_state.get('insights_id', ''))\n",
    "#     print(\"\\n‚úÖ Final Summary:\\n\", summary or \"Not generated.\")\n",
    "#     print(\"\\n‚úÖ Final Insights:\\n\", insights or \"Not generated.\")\n",
    "    \n",
    "#     print(\"\\n‚úÖ Extracted Action Items:\")\n",
    "#     action_item_ids = final_state.get('action_items_ids', [])\n",
    "#     if not action_item_ids:\n",
    "#         print(\"  - No action items were processed.\")\n",
    "#     else:\n",
    "#         for item_id in action_item_ids:\n",
    "#             action_items = DataStorage.retrieve('action_items', item_id)\n",
    "#             if action_items:\n",
    "#                 for i, item in enumerate(action_items):\n",
    "#                     print(f\"  - Task: {item.task}, Owner: {item.owner}, Deadline: {item.deadline}\")\n",
    "#             else:\n",
    "#                 print(f\"  - Could not retrieve action items for ID: {item_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70febf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f6160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "# #     # This is a simple test to show how the node works in isolation\n",
    "#     test_state = GraphState(\n",
    "#         document_content=\"Meeting Minutes - July 21, 2025\\nAttendees: Alice, Bob, Charlie\\n1. Project Phoenix Update: Bob confirmed the new server is deployed. Alice raised a concern about the budget overrun. It was decided to review the Q3 budget next week. Action Item: Charlie to schedule a budget review meeting by Friday, July 25th.\\n2. Marketing Campaign: Discussed the new 'Summer Sale' campaign. It will launch on August 1st. All assets are ready.\",\n",
    "#         summary_status=\"pending\",\n",
    "#         insights_status=\"pending\",\n",
    "#         summary_output=\"\",\n",
    "#         insights_output=\"\",\n",
    "#         iteration=0,\n",
    "#         error_message=\"\",\n",
    "#         current_reasoning=\"\",\n",
    "#         next=\"\"\n",
    "#     )\n",
    "\n",
    "#     result_update = run_summary_agent_agentic(test_state)\n",
    "#     print(\"\\n--- TEST RESULT ---\")\n",
    "#     import json\n",
    "#     print(json.dumps(result_update, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cf294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa449746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bc7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0919dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_summary_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     An agentic node that intelligently generates a meeting summary.\n",
    "#     It has a specific persona, instructions, and robust error handling.\n",
    "#     \"\"\"\n",
    "#     print(\"\\nü§ñ Agentic Summary Node Called...\")\n",
    "\n",
    "#     # 1. Define the Agent's Persona and Mission via a System Prompt\n",
    "#     system_prompt = \"\"\"\n",
    "#     You are an expert Meeting Summarization Agent. Your sole mission is to create a concise, structured, and insightful summary from the provided meeting minutes.\n",
    "#     If you identify any specific tasks assigned to people (action items), Do include the action items directly in your final summary. Also, you MUST use the 'extract_and_store_action_items' tool to process them. you can mention that action items were noted and processed separately.\n",
    "\n",
    "#     ## Your Guidelines:\n",
    "#     1.  **Identify Core Content**: Focus on extracting the most critical information:\n",
    "#         - **Key Decisions Made**: What was formally decided?\n",
    "#         - **Action Items**: What are the specific next steps? Who is responsible (owner)? What are the deadlines?\n",
    "#         - **Major Topics Discussed**: Briefly mention the main subjects of conversation.\n",
    "#         - **Outcomes & Resolutions**: What was the final result of the discussions?\n",
    "\n",
    "#     2.  **Prioritize Significance**: Do not just list topics in order. Your value is in identifying what truly matters. A brief 2-minute decision that sets the company's direction is more important than a 30-minute unresolved debate.\n",
    "\n",
    "#     3.  **Structure the Output**: Present the summary in a clean, professional format using Markdown. Use headings (#), subheadings (##), and bullet points (-) for clarity.\n",
    "\n",
    "#     4.  **Be Objective**: Summarize what was said and decided without adding your own opinions or interpretations. Stick to the facts presented in the document.\n",
    "\n",
    "#     Your final output should be ONLY the structured summary, ready to be shared with meeting attendees.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 2. Setup the Agent using the working pattern from your previous code\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system_prompt),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     ])\n",
    "\n",
    "#     groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "#     if not groq_api_key:\n",
    "#         raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "#     llm = ChatGroq(temperature=0, model=\"qwen/qwen3-32b\")\n",
    "\n",
    "#     # Use the same pattern as your working code\n",
    "#     tools = [extract_and_store_action_items]\n",
    "#     agent = create_react_agent(\n",
    "#         model=llm,  # Using model parameter like your working code\n",
    "#         tools=tools,\n",
    "#         prompt=prompt\n",
    "#     )\n",
    "\n",
    "#     # 3. Invoke the Agent with Error Handling\n",
    "#     try:\n",
    "#         document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "#         if not document_content:\n",
    "#             raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "        \n",
    "#         print(\"üß† Agent is thinking and generating the summary...\")\n",
    "        \n",
    "#         # Create messages in the format the agent expects\n",
    "#         messages = [HumanMessage(content=f\"Please generate a summary for the following meeting minutes:\\n\\n---\\n\\n{document_content}\")]\n",
    "        \n",
    "#         # Invoke using the same pattern as your working code\n",
    "#         result = agent.invoke({\"messages\": messages})\n",
    "\n",
    "#         # Extract the generated summary\n",
    "#         generated_summary = result['messages'][-1].content\n",
    "#         print(\"‚úÖ Summary Agent: Generated summary successfully.\")\n",
    "        \n",
    "#         # Store the generated summary\n",
    "#         summary_id = DataStorage.store('summary_output', generated_summary)\n",
    "        \n",
    "#         return {\n",
    "#             \"summary_status\": \"success\",\n",
    "#             \"summary_id\": summary_id,\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in Agentic Summary Node: {e}\")\n",
    "        \n",
    "#         # If the agent fails, report the failure back to the graph state\n",
    "#         return {\n",
    "#             \"summary_status\": \"failed\",\n",
    "#             \"error_message\": f\"Summary Agent Error: {str(e)}\"\n",
    "#         }\n",
    "\n",
    "\n",
    "# def run_insights_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     An agentic node that generates intelligent insights from meeting minutes.\n",
    "#     \"\"\"\n",
    "#     print(\"\\nü§ñ Agentic Insights Node Called...\")\n",
    "\n",
    "#     # 1. Define the Agent's Persona and Mission via a System Prompt\n",
    "#     system_prompt = \"\"\"\n",
    "#     You are an expert Meeting Insights Agent. Your mission is to analyze meeting minutes and extract meaningful patterns, strategic implications, and actionable intelligence.\n",
    "\n",
    "#     ## Your Analysis Framework:\n",
    "#     1. **Strategic Insights**: What are the long-term implications of the decisions made?\n",
    "#     2. **Pattern Recognition**: Are there recurring themes, concerns, or opportunities?\n",
    "#     3. **Risk Assessment**: What potential challenges or obstacles were identified?\n",
    "#     4. **Stakeholder Analysis**: Who are the key players and what are their positions?\n",
    "#     5. **Follow-up Opportunities**: What questions remain unanswered or need further exploration?\n",
    "\n",
    "#     ## Output Guidelines:\n",
    "#     - Present insights in a structured, analytical format using Markdown\n",
    "#     - Focus on what's NOT immediately obvious from a simple reading\n",
    "#     - Provide context and implications, not just facts\n",
    "#     - Be strategic and forward-thinking in your analysis\n",
    "#     - Use professional language suitable for executive briefings\n",
    "\n",
    "#     Your final output should be a comprehensive insights report ready for leadership review.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 2. Setup the Agent using the working pattern\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system_prompt),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     ])\n",
    "\n",
    "#     groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "#     if not groq_api_key:\n",
    "#         raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "#     llm = ChatGroq(temperature=0.1, model=\"llama3-70b-8192\")\n",
    "\n",
    "#     # This agent doesn't need tools, keeping it focused on analysis\n",
    "#     insights_agent = create_react_agent(\n",
    "#         model=llm,\n",
    "#         tools=[],  # No tools needed for insights\n",
    "#         prompt=prompt\n",
    "#     )\n",
    "\n",
    "#     # 3. Invoke the Agent with Error Handling\n",
    "#     try:\n",
    "#         document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "#         if not document_content:\n",
    "#             raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "        \n",
    "#         print(\"üß† Insights Agent is analyzing the meeting...\")\n",
    "        \n",
    "#         # Create messages in the format the agent expects\n",
    "#         messages = [HumanMessage(content=f\"Please analyze and generate insights for the following meeting minutes:\\n\\n---\\n\\n{document_content}\")]\n",
    "        \n",
    "#         # Invoke the agent\n",
    "#         result = insights_agent.invoke({\"messages\": messages})\n",
    "\n",
    "#         # Extract the generated insights\n",
    "#         generated_insights = result['messages'][-1].content\n",
    "#         print(\"‚úÖ Insights Agent: Generated insights successfully.\")\n",
    "        \n",
    "#         # Store the generated insights\n",
    "#         insights_id = DataStorage.store('insights_output', generated_insights)\n",
    "        \n",
    "#         return {\n",
    "#             \"insights_status\": \"success\",\n",
    "#             \"insights_id\": insights_id,\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in Agentic Insights Node: {e}\")\n",
    "        \n",
    "#         return {\n",
    "#             \"insights_status\": \"failed\",\n",
    "#             \"error_message\": f\"Insights Agent Error: {str(e)}\"\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b012c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32c5b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Keep your original agent functions - they're fine\n",
    "# def run_summary_agent(state: GraphState) -> GraphState:\n",
    "#     \"\"\"Summary agent - focused on meeting summary\"\"\"\n",
    "#     print(f\"\\nüìù Summary Agent working on meeting minutes...\")\n",
    "#     new_state = state.copy()\n",
    "    \n",
    "#     # Simulate work with some intelligence about content\n",
    "#     success_rate = 0.1 if \"meeting\" in state['document_content'].lower() else 0.3\n",
    "    \n",
    "#     if random.random() < success_rate:\n",
    "#         new_state['summary_status'] = \"success\"\n",
    "#         new_state['summary_output'] = f\"Meeting Summary: Key decisions and action items extracted from meeting minutes (iteration {state['iteration']})\"\n",
    "#         print(\"‚úÖ Summary: Generated meeting summary successfully\")\n",
    "#     else:\n",
    "#         new_state['summary_status'] = \"failed\" \n",
    "#         new_state['summary_output'] = \"Summary generation failed\"\n",
    "#         new_state['error_message'] = \"Temporary API issue during summary generation\"\n",
    "#         print(\"‚ùå Summary: Failed (likely temporary issue)\")\n",
    "    \n",
    "#     time.sleep(1)\n",
    "#     return new_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91540ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def run_insights_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     Insights agent - focused on meeting insights.\n",
    "#     FIX: Now returns a dictionary and clears the error message on success.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\nüîç Insights Agent extracting key insights...\")\n",
    "    \n",
    "#     # Simulate work\n",
    "#     success_rate = 0.6 if \"meeting\" in state['document_content'].lower() else 0.3\n",
    "#     time.sleep(1)\n",
    "\n",
    "#     if random.random() < success_rate:\n",
    "#         print(\"‚úÖ Insights: Extracted meeting insights successfully\")\n",
    "#         # On success, return a success status AND an empty error message\n",
    "#         return {\n",
    "#             \"insights_status\": \"success\",\n",
    "#             \"insights_output\": f\"Meeting Insights: Key themes and decisions identified (iteration {state['iteration']})\",\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "#     else:\n",
    "#         print(\"‚ùå Insights: Failed (simulating temporary issue)\")\n",
    "#         # On failure, return a failed status AND a descriptive error message\n",
    "#         return {\n",
    "#             \"insights_status\": \"failed\",\n",
    "#             \"insights_output\": \"Insights generation failed\",\n",
    "#             \"error_message\": \"Temporary processing issue during insights extraction\"\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# def run_both_parallel_agents(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     Runs summary and insights agents in parallel.\n",
    "#     This now calls both of the new agentic nodes.\n",
    "#     \"\"\"\n",
    "#     print(\"\\n---RUNNING BOTH AGENTIC NODES IN PARALLEL---\")\n",
    "\n",
    "#     parallel_runnable = RunnableParallel(\n",
    "#         summary_result=run_summary_agent,\n",
    "#         insights_result=run_insights_agent \n",
    "#     )\n",
    "\n",
    "#     parallel_results = parallel_runnable.invoke(state)\n",
    "\n",
    "#     summary_updates = parallel_results['summary_result']\n",
    "#     insights_updates = parallel_results['insights_result']\n",
    "\n",
    "#     combined_updates = {**summary_updates, **insights_updates}\n",
    "\n",
    "#     summary_error = summary_updates.get(\"error_message\", \"\")\n",
    "#     insights_error = insights_updates.get(\"error_message\", \"\")\n",
    "\n",
    "#     if summary_error and insights_error:\n",
    "#         combined_updates[\"error_message\"] = f\"Summary Error: {summary_error} | Insights Error: {insights_error}\"\n",
    "#     elif summary_error:\n",
    "#         combined_updates[\"error_message\"] = summary_error\n",
    "#     elif insights_error:\n",
    "#         combined_updates[\"error_message\"] = insights_error\n",
    "#     else:\n",
    "#         combined_updates[\"error_message\"] = \"\"\n",
    "\n",
    "#     return combined_updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartcopilot-api (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
