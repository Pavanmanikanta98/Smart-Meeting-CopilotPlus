{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4d4347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b9fd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import TypedDict, Literal, List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8134d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "950b3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Storage ---\n",
    "# This class simulates a database or key-value store.\n",
    "# In production, this could be replaced with Redis, a file system, or a database.\n",
    "class DataStorage:\n",
    "    \"\"\"Simulates a database. In production, replace with Redis, a DB, etc.\"\"\"\n",
    "    _storage = {\n",
    "        'document_content': {},\n",
    "        'summary_output': {},\n",
    "        'insights_output': {},\n",
    "        'action_items': {}\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def store(cls, data_type: str, data: any) -> str:\n",
    "        \"\"\"Store data and return a unique reference ID.\"\"\"\n",
    "        # Using a simple timestamp and random number for a unique ID\n",
    "        uid = f\"{data_type}_{int(time.time() * 1000)}_{random.randint(100, 999)}\"\n",
    "        cls._storage[data_type][uid] = data\n",
    "        print(f\"📦 Stored data of type '{data_type}' with ID: {uid}\")\n",
    "        return uid\n",
    "    \n",
    "    @classmethod\n",
    "    def retrieve(cls, data_type: str, uid: str) -> any:\n",
    "        \"\"\"Retrieve data by its reference ID.\"\"\"\n",
    "        print(f\" retrievel data of type '{data_type}' with ID: {uid}\")\n",
    "        return cls._storage[data_type].get(uid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b8ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ea4696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Refactored GraphState ---\n",
    "# The state now holds lightweight IDs instead of large text blobs.\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"Refactored state using IDs for scalability.\"\"\"\n",
    "    document_content_id: str\n",
    "    summary_status: str\n",
    "    insights_status: str\n",
    "    summary_output_id: Optional[str]\n",
    "    insights_output_id: Optional[str]\n",
    "    action_items_ids: List[str]\n",
    "    iteration: int\n",
    "    error_message: str\n",
    "    current_reasoning: str\n",
    "    next: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79ab7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Item Extraction Tool \n",
    "class ActionItem(BaseModel):\n",
    "    task: str = Field(description=\"The specific action or task to be completed.\")\n",
    "    owner: Optional[str] = Field(description=\"The person or team responsible for the task.\")\n",
    "    deadline: Optional[str] = Field(description=\"The due date for the task, e.g., 'EOW', '2024-08-15'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a560b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple but intelligent decision model\n",
    "class SupervisorDecision(BaseModel):\n",
    "    \"\"\"AI Supervisor decision with intelligent reasoning\"\"\"\n",
    "    next_action: Literal[\n",
    "        \"call_both_parallel\", \n",
    "        \"call_summary_only\", \n",
    "        \"call_insights_only\", \n",
    "        \"end_workflow\"\n",
    "    ] = Field(description=\"What to do next in the workflow\")\n",
    "    \n",
    "    reasoning: str = Field(description=\"Why this decision makes sense for the workflow goal\")\n",
    "    \n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence in this decision (0.0 to 1.0)\", \n",
    "        ge=0.0, le=1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da360cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tool will be used by our agents.\n",
    "@tool\n",
    "def extract_and_store_action_items(document_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Identifies action items in a document, structures them,\n",
    "    stores them in the DataStorage, and returns a confirmation.\n",
    "    \"\"\"\n",
    "    print(\"\\n🛠️ Action Item Tool Called...\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert at extracting structured data. Your task is to identify all action items from the provided text. For each action item, extract the task description, the owner, and the deadline. If any of these details are missing for an item, use 'N/A'.\"),\n",
    "        (\"human\", \"Please extract all action items from this document:\\n\\n---\\n\\n{document}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
    "\n",
    "    # extractor = prompt | llm.with_structured_output(schema=ActionItem)\n",
    "    \n",
    "    # try:\n",
    "    #     result = extractor.invoke({\"document\": document_content})\n",
    "    #     action_items_list = result.action_items if result and hasattr(result, \"action_items\") else []\n",
    "    \n",
    "    # Use with_structured_output to get clean JSON\n",
    "    extractor = prompt | llm.with_structured_output(schema=List[ActionItem])\n",
    "    \n",
    "    try:\n",
    "        result = extractor.invoke({\"document\": document_content})\n",
    "        action_items_list = result.action_items if result and hasattr(result, \"action_items\") else []\n",
    "        if not action_items_list:\n",
    "            return \"No action items were found in the document.\"\n",
    "            \n",
    "        # Store the list of Pydantic objects\n",
    "        storage_id = DataStorage.store('action_items', action_items_list)\n",
    "        print(f\"✅ Action items extracted and stored successfully.\")\n",
    "        return f\"Successfully extracted and stored {len(action_items_list)} action items with ID: {storage_id}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in Action Item Tool: {e}\")\n",
    "        return \"An error occurred while trying to extract action items.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1af35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "def intelligent_supervisor(state: GraphState) ->  Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Smart supervisor that understands the workflow goal:\n",
    "    - Get meeting minutes summary \n",
    "    - Get key insights in parallel\n",
    "    - Be intelligent about when to retry vs when to finish\n",
    "    \"\"\"\n",
    "    print(f\"\\n🧠 AI Supervisor thinking... (Iteration: {state['iteration']})\")\n",
    "    \n",
    "    # Enhanced ReAct-style system prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are an intelligent workflow supervisor using ReAct (Reasoning + Acting) methodology. \n",
    "\n",
    "    ## YOUR MISSION:\n",
    "    Ensure we successfully get:\n",
    "    1. A good SUMMARY of the meeting minutes\n",
    "    2. KEY INSIGHTS from the meeting minutes\n",
    "    3. Both delivered EFFICIENTLY\n",
    "\n",
    "    ## ReAct PROCESS - Think step by step:\n",
    "\n",
    "    **THOUGHT**: First, analyze the current workflow state. What's working? What failed? Why might it have failed?\n",
    "\n",
    "    **OBSERVATION**: What do you observe about the current status? Look at:\n",
    "    - What agents have succeeded/failed\n",
    "    - How many iterations we've done  \n",
    "    - Whether failures seem temporary (network/API issues) or persistent\n",
    "    - If we have partial success that might be sufficient\n",
    "\n",
    "    **ACTION**: Based on your thought and observation, decide the smartest next action for our meeting processing goal.\n",
    "\n",
    "    ## CURRENT WORKFLOW STATE:\n",
    "    - Meeting Document: \"{doc_preview}\"\n",
    "    - Summary Status: {summary_status}\n",
    "    - Insights Status: {insights_status} \n",
    "    - Current Iteration: {iteration}\n",
    "    - Last Error: {error_msg}\n",
    "\n",
    "    ## AVAILABLE ACTIONS:\n",
    "    - call_both_parallel: Run both agents simultaneously (efficient for fresh start or when both need work)\n",
    "    - call_summary_only: Focus only on getting the meeting summary\n",
    "    - call_insights_only: Focus only on getting meeting insights  \n",
    "    - end_workflow: We have achieved our goal (both summary + insights ready)\n",
    "\n",
    "    ## INTELLIGENT DECISION GUIDELINES:\n",
    "    - Iteration 1: Usually start with parallel execution for efficiency\n",
    "    - One success, one failure: Target retry the failed agent only\n",
    "    - Both failed early iterations: Likely temporary issues, retry both\n",
    "    - Multiple failures: Consider if we should accept partial results or continue\n",
    "    - Both successful: Mission accomplished!\n",
    "\n",
    "    **Remember**: You're optimizing for getting useful meeting analysis (summary + insights), not perfect success rates.\n",
    "\n",
    "    Use the ReAct process: THOUGHT → OBSERVATION → ACTION with clear reasoning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Format the prompt with current state\n",
    "    doc_preview = state['document_content'][:100] + \"...\" if len(state['document_content']) > 100 else state['document_content']\n",
    "    \n",
    "    formatted_prompt = system_prompt.format(\n",
    "        doc_preview=doc_preview,\n",
    "        summary_status=state['summary_status'],\n",
    "        insights_status=state['insights_status'], \n",
    "        iteration=state['iteration'],\n",
    "        error_msg=state['error_message'] or \"None\"\n",
    "    )\n",
    "    \n",
    "    # Setup Groq API with Qwen model\n",
    "    groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "    \n",
    "    os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        temperature=0,\n",
    "        model=\"deepseek-r1-distill-llama-70b\"  \n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Use ReAct methodology: THOUGHT → OBSERVATION → ACTION. Analyze the workflow state and decide what to do next for our meeting processing goal. Think step by step.\")\n",
    "    ]\n",
    "    \n",
    "    # Get structured decision from LLM\n",
    "    try:\n",
    "        decision = llm.with_structured_output(SupervisorDecision).invoke(messages)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ LLM call failed: {e}\")\n",
    "        # Fallback to simulation if LLM fails\n",
    "        decision = simulate_smart_decision(state)\n",
    "    \n",
    "    # # Simulate intelligent decision (replace with real LLM)\n",
    "    # decision = simulate_smart_decision(state)\n",
    "    \n",
    "    print(f\"💭 AI Reasoning: {decision.reasoning}\")\n",
    "    print(f\"⚡ Decision: {decision.next_action} (confidence: {decision.confidence:.2f})\")\n",
    "    \n",
    "    # # Update state with AI reasoning\n",
    "    # new_state = state.copy()\n",
    "    # new_state['next'] = decision.next_action  # Store the next action\n",
    "    # new_state['current_reasoning'] = decision.reasoning\n",
    "    \n",
    "    # return decision.next_action if decision.next_action != \"end_workflow\" else END\n",
    "    goto = decision.next_action if decision.next_action != \"end_workflow\" else END\n",
    "\n",
    "    print('goto:',goto)\n",
    "\n",
    "    return {\n",
    "        \"current_reasoning\": decision.reasoning,\n",
    "        \"next\": decision.next_action # Store the determined next action\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38bc4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simulate_smart_decision(state: GraphState) -> SupervisorDecision:\n",
    "    \"\"\"\n",
    "    Simulate what an intelligent model like Qwen would decide\n",
    "    This is just simulation - replace with actual LLM call\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_status = state['summary_status']\n",
    "    insights_status = state['insights_status']\n",
    "    iteration = state['iteration']\n",
    "    \n",
    "    # Smart decision making that a good reasoning model would do\n",
    "    \n",
    "    # Goal achieved - both successful\n",
    "    if summary_status == \"success\" and insights_status == \"success\":\n",
    "        return SupervisorDecision(\n",
    "            next_action=\"end_workflow\",\n",
    "            reasoning=\"Perfect! Both summary and insights are ready. Our workflow goal is complete - we have meeting summary + key insights as requested.\",\n",
    "            confidence=1.0\n",
    "        )\n",
    "    \n",
    "    # First iteration - start efficiently  \n",
    "    if iteration == 1 and summary_status == \"pending\" and insights_status == \"pending\":\n",
    "        return SupervisorDecision(\n",
    "            next_action=\"call_both_parallel\", \n",
    "            reasoning=\"First attempt - running both summary and insights agents in parallel for efficiency. This is the optimal starting strategy.\",\n",
    "            confidence=0.9\n",
    "        )\n",
    "    \n",
    "    # One succeeded, one failed - targeted retry\n",
    "    if summary_status == \"success\" and insights_status == \"failed\":\n",
    "        if iteration <= 3:  # Smart about retry limits\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_insights_only\",\n",
    "                reasoning=\"Summary is ready, but insights failed. Retrying only insights agent since summary is already successful. Efficient targeted approach.\",\n",
    "                confidence=0.8\n",
    "            )\n",
    "        else:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"end_workflow\",\n",
    "                reasoning=\"Summary is ready and we've tried insights multiple times. Sometimes partial success is acceptable for meeting processing workflow.\",\n",
    "                confidence=0.6\n",
    "            )\n",
    "    \n",
    "    if insights_status == \"success\" and summary_status == \"failed\":\n",
    "        if iteration <= 3:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_summary_only\", \n",
    "                reasoning=\"Insights are ready, but summary failed. Retrying only summary agent since insights are already successful. Focused retry approach.\",\n",
    "                confidence=0.8\n",
    "            )\n",
    "        else:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"end_workflow\",\n",
    "                reasoning=\"Insights are ready and we've tried summary multiple times. We have key insights from the meeting which provides value.\",\n",
    "                confidence=0.6\n",
    "            )\n",
    "    \n",
    "    # Both failed - intelligent retry decision\n",
    "    if summary_status == \"failed\" and insights_status == \"failed\":\n",
    "        if iteration <= 2:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_both_parallel\",\n",
    "                reasoning=\"Both agents failed, but it's early in the process. Likely a temporary issue (network/API). Retrying both in parallel - efficient recovery approach.\",\n",
    "                confidence=0.7\n",
    "            )\n",
    "        elif iteration <= 4:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"call_both_parallel\", \n",
    "                reasoning=\"Multiple failures but still within reasonable retry range. The meeting document seems valid, so this might be temporary service issues. One more parallel attempt.\",\n",
    "                confidence=0.5\n",
    "            )\n",
    "        else:\n",
    "            return SupervisorDecision(\n",
    "                next_action=\"end_workflow\",\n",
    "                reasoning=\"After multiple attempts, continuing may not be productive. This could be a deeper issue with the document format or service availability. Ending workflow.\",\n",
    "                confidence=0.8\n",
    "            )\n",
    "    \n",
    "    # Default intelligent fallback\n",
    "    return SupervisorDecision(\n",
    "        next_action=\"call_both_parallel\",\n",
    "        reasoning=\"Current state requires both agents to run. Taking parallel approach for efficiency in meeting processing workflow.\", \n",
    "        confidence=0.6\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "684ebd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_supervisor_decision(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the decision stored by the intelligent supervisor.\n",
    "    \"\"\"\n",
    "    return state['next'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04071fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_summary_agent(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    An agentic node that intelligently generates a meeting summary.\n",
    "    It has a specific persona, instructions, and robust error handling.\n",
    "    \"\"\"\n",
    "    print(\"\\n🤖 Agentic Summary Node Called...\")\n",
    "\n",
    "    # 1. Define the Agent's Persona and Mission via a System Prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert Meeting Summarization Agent. Your sole mission is to create a concise, structured, and insightful summary from the provided meeting minutes.\n",
    "    If you identify any specific tasks assigned to people (action items), Do include the action items directly in your final summary. Also, you MUST use the 'extract_and_store_action_items' tool to process them. you can mention that action items were noted and processed separately.\n",
    "\n",
    "    ## Your Guidelines:\n",
    "    1.  **Identify Core Content**: Focus on extracting the most critical information:\n",
    "        - **Key Decisions Made**: What was formally decided?\n",
    "        - **Action Items**: What are the specific next steps? Who is responsible (owner)? What are the deadlines?\n",
    "        - **Major Topics Discussed**: Briefly mention the main subjects of conversation.\n",
    "        - **Outcomes & Resolutions**: What was the final result of the discussions?\n",
    "\n",
    "    2.  **Prioritize Significance**: Do not just list topics in order. Your value is in identifying what truly matters. A brief 2-minute decision that sets the company's direction is more important than a 30-minute unresolved debate.\n",
    "\n",
    "    3.  **Structure the Output**: Present the summary in a clean, professional format using Markdown. Use headings (#), subheadings (##), and bullet points (-) for clarity.\n",
    "\n",
    "    4.  **Be Objective**: Summarize what was said and decided without adding your own opinions or interpretations. Stick to the facts presented in the document.\n",
    "\n",
    "    Your final output should be ONLY the structured summary, ready to be shared with meeting attendees.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2. Setup the Agent\n",
    "    # For this task, the agent doesn't need external tools. Its \"tool\" is its own\n",
    "    # reasoning capability applied to the text. We use the ReAct agent structure\n",
    "    # for its robust reasoning loop, even with an empty tool list.\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Please generate a summary for the following meeting minutes:\\n\\n---\\n\\n{{document_content}}\")\n",
    "    ])\n",
    "\n",
    "    groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "    llm = ChatGroq(temperature=0, model=\"qwen/qwen3-32b\")\n",
    "\n",
    "    # The agent uses the LLM and prompt, with no external tools needed for this task.\n",
    "    summary_agent = create_react_agent(llm, tools=[extract_and_store_action_items], prompt=prompt)\n",
    "\n",
    "    # 3. Invoke the Agent with Error Handling\n",
    "    try:\n",
    "        document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "        if not document_content:\n",
    "            raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "        \n",
    "        print(\"🧠 Agent is thinking and generating the summary...\")\n",
    "        # The input to the agent is the document content from DataStorage\n",
    "        # This allows the agent to work with a lightweight reference ID instead of large text blobs.\n",
    "        # This is more scalable and efficient for large documents.\n",
    "        agent_input = {\"meeting_minutes\": document_content}\n",
    "        result = summary_agent.invoke(agent_input)\n",
    "\n",
    "        # print(\"result:\", result['messages'][-1].content)\n",
    "\n",
    "        # The agent's final answer is in the last message of the result\n",
    "        generated_summary = result['messages'][-1].content\n",
    "        print(\"✅ Summary Agent: Generated summary successfully.\")\n",
    "        \n",
    "        # Store the generated summary\n",
    "        summary_id = DataStorage.store('summary_output', generated_summary)\n",
    "        \n",
    "        return {\n",
    "            \"summary_status\": \"success\",\n",
    "            \"summary_output_id\": summary_id,\n",
    "            \"error_message\": \"\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in Agentic Summary Node: {e}\")\n",
    "        \n",
    "        # If the agent fails, report the failure back to the graph state\n",
    "        return {\n",
    "            \"summary_status\": \"failed\",\n",
    "            \"error_message\": f\"Summary Agent Error: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9de7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f7bce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_insights_agent(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    An agentic node that intelligently extracts key insights from meeting minutes.\n",
    "    It has a specific persona, instructions, and robust error handling.\n",
    "    \"\"\"\n",
    "    print(\"\\n🤖 Agentic Insights Node Called...\")\n",
    "\n",
    "    # 1. Define the Agent's Persona and Mission via a System Prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert Meeting Insights Agent. Your mission is to extract not just facts, but the underlying meaning and implications of decisions, and strategic insights from the meeting minutes. You are focused on the 'why' and 'so what', not just the 'what'. You do not need to process action items.\n",
    "\n",
    "    ## Your Guidelines:\n",
    "    1. **Identify Key Themes**: Go beyond topics. What are the recurring ideas, concerns, or strategic directions? (e.g., \"A recurring theme was the concern over budget constraints affecting timelines.\")\n",
    "    2. **Highlight Critical Decisions & Implications**: State the decision and then explain *why it matters*. (e.g., \"Decision: Approved 15% marketing budget increase. Implication: This signals a strategic shift towards aggressive market capture for the new product.\")\n",
    "    3. **Surface Actionable Insights**: What can the team learn or do differently based on the discussion? These are not the same as action items. (e.g., \"Insight: The debate on resource allocation suggests a lack of clarity in departmental priorities, which should be addressed.\")\n",
    "    4. **Structure the Output**: Present insights in a clear, professional format using Markdown. Use headings and bullet points.\n",
    "\n",
    "    Your final output should be ONLY the structured insights, ready for strategic review.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2. Setup the Agent\n",
    "    # TODO: The variable in the prompt must match the key used in the 'invoke' call.\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Please extract key insights from the following meeting minutes:\\n\\n---\\n\\n{{document_content}}\")\n",
    "    ])\n",
    "\n",
    "    groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"GROQ_API_KEY environment variable is not set\")\n",
    "\n",
    "    llm = ChatGroq(temperature=0.1, model=\"llama3-70b-8192\")\n",
    "\n",
    "    # # This agent doesn't need the action item tool, keeping it focused.\n",
    "    insights_agent = create_react_agent(llm, tools=[], prompt=prompt)\n",
    "\n",
    "    # 3. Invoke the Agent with Error Handling\n",
    "    try:\n",
    "        document_content = DataStorage.retrieve('document_content', state['document_content_id'])\n",
    "        if not document_content:\n",
    "            raise ValueError(\"Failed to retrieve document content from storage.\")\n",
    "        \n",
    "        print(\"🧠 Agent is thinking and extracting insights...\")\n",
    "        agent_input = {\"meeting_minutes\": document_content}\n",
    "        result = insights_agent.invoke(agent_input)\n",
    "\n",
    "        # The agent's final answer is in the last message of the result\n",
    "        generated_insights = result['messages'][-1].content\n",
    "        print(\"✅ Insights Agent: Extracted insights successfully.\")\n",
    "        \n",
    "        # Store the generated insights\n",
    "        insights_id = DataStorage.store('insights_output', generated_insights)\n",
    "        \n",
    "        return {\n",
    "            \"insights_status\": \"success\",\n",
    "            \"insights_output_id\": insights_id,\n",
    "            \"error_message\": \"\"\n",
    "        }\n",
    "\n",
    "    except (KeyError, IndexError, Exception) as e:\n",
    "        print(f\"❌ Error in Agentic Insights Node: {e}\")\n",
    "        \n",
    "        # If the agent fails, report the failure back to the graph state\n",
    "        return {\n",
    "            \"insights_status\": \"failed\",\n",
    "            \"error_message\": f\"Insights Agent Error: {str(e)}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# def run_both_parallel_agents(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     Runs summary and insights agents in parallel.\n",
    "#     This now calls both of the new agentic nodes.\n",
    "#     \"\"\"\n",
    "#     print(\"\\n---RUNNING BOTH AGENTIC NODES IN PARALLEL---\")\n",
    "\n",
    "#     parallel_runnable = RunnableParallel(\n",
    "#         summary_result=run_summary_agent,\n",
    "#         insights_result=run_insights_agent \n",
    "#     )\n",
    "\n",
    "#     parallel_results = parallel_runnable.invoke(state)\n",
    "\n",
    "#     summary_updates = parallel_results['summary_result']\n",
    "#     insights_updates = parallel_results['insights_result']\n",
    "\n",
    "#     combined_updates = {**summary_updates, **insights_updates}\n",
    "\n",
    "#     summary_error = summary_updates.get(\"error_message\", \"\")\n",
    "#     insights_error = insights_updates.get(\"error_message\", \"\")\n",
    "\n",
    "#     if summary_error and insights_error:\n",
    "#         combined_updates[\"error_message\"] = f\"Summary Error: {summary_error} | Insights Error: {insights_error}\"\n",
    "#     elif summary_error:\n",
    "#         combined_updates[\"error_message\"] = summary_error\n",
    "#     elif insights_error:\n",
    "#         combined_updates[\"error_message\"] = insights_error\n",
    "#     else:\n",
    "#         combined_updates[\"error_message\"] = \"\"\n",
    "\n",
    "#     return combined_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "304047ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_both_parallel_agents(state: GraphState) -> dict:\n",
    "    \"\"\"Runs the refactored summary and insights agents in parallel.\"\"\"\n",
    "    print(\"\\n---RUNNING BOTH REFACTORED AGENTS IN PARALLEL---\")\n",
    "\n",
    "    parallel_runnable = RunnableParallel(\n",
    "        summary_result=run_summary_agent,\n",
    "        insights_result=run_insights_agent\n",
    "    )\n",
    "    parallel_results = parallel_runnable.invoke(state)\n",
    "    \n",
    "    # This combination logic remains the same and works with the new outputs\n",
    "    return {**parallel_results['summary_result'], **parallel_results['insights_result']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4373f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_iteration(state: GraphState) -> GraphState:\n",
    "    \"\"\"Track iterations for intelligent decision making\"\"\"\n",
    "    new_state = state.copy()\n",
    "    new_state['iteration'] += 1\n",
    "    print(f\"\\n--- Workflow Iteration: {new_state['iteration']} ---\")\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1b789c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7db48c53e360>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the workflow graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"increment_iteration\", increment_iteration)\n",
    "workflow.add_node(\"intelligent_supervisor\", intelligent_supervisor)\n",
    "workflow.add_node(\"run_summary_agent\", run_summary_agent)\n",
    "workflow.add_node(\"run_insights_agent\", run_insights_agent)\n",
    "workflow.add_node(\"run_parallel_agents\", run_both_parallel_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46e59386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7db48c53e360>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"increment_iteration\")\n",
    "\n",
    "# Define initial edge from entry point to supervisor\n",
    "workflow.add_edge(\"increment_iteration\", \"intelligent_supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4bad92f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7db48c53e360>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The AI supervisor makes intelligent routing decisions\n",
    "# - The edge starts from the 'intelligent_supervisor' node.\n",
    "# - The 'route_supervisor_decision' function defines how to choose the next path.\n",
    "workflow.add_conditional_edges(\n",
    "    \"intelligent_supervisor\",     # Conditional edges originate from the 'intelligent_supervisor' node\n",
    "    route_supervisor_decision,    # This function defines the routing logic (returns the key for the dict)\n",
    "    {\n",
    "        \"call_both_parallel\": \"run_parallel_agents\", # Map decision to the parallel execution node\n",
    "        \"call_insights_only\": \"run_insights_agent\",  # Map decision to the insights agent node\n",
    "        \"call_summary_only\": \"run_summary_agent\",    # Map decision to the summary agent node\n",
    "        \"end_workflow\": END                          # Map decision to the END state\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebdc0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7db48c53e360>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After each agent completes, return to the supervisor for the next intelligent decision\n",
    "workflow.add_edge(\"run_summary_agent\", \"intelligent_supervisor\")\n",
    "workflow.add_edge(\"run_insights_agent\", \"intelligent_supervisor\")\n",
    "workflow.add_edge(\"run_parallel_agents\", \"intelligent_supervisor\") # Add this edge for parallel execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0d9a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Intelligent Meeting Processing Workflow\n",
      "\n",
      "--- Workflow Iteration: 1 ---\n",
      "\n",
      "📊 Current State: {'increment_iteration': {'summary_status': 'pending', 'insights_status': 'pending', 'iteration': 1, 'error_message': '', 'current_reasoning': '', 'next': ''}}\n",
      "\n",
      "🧠 AI Supervisor thinking... (Iteration: 1)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'document_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      4\u001b[39m initial_state = GraphState(\n\u001b[32m      5\u001b[39m         document_content=\u001b[33m\"\u001b[39m\u001b[33mMeeting Minutes - July 21, 2025\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAttendees: Alice, Bob, Charlie\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m1. Project Phoenix Update: Bob confirmed the new server is deployed. Alice raised a concern about the budget overrun. It was decided to review the Q3 budget next week. Action Item: Charlie to schedule a budget review meeting by Friday, July 25th.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m2. Marketing Campaign: Discussed the new \u001b[39m\u001b[33m'\u001b[39m\u001b[33mSummer Sale\u001b[39m\u001b[33m'\u001b[39m\u001b[33m campaign. It will launch on August 1st. All assets are ready.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m         summary_status=\u001b[33m\"\u001b[39m\u001b[33mpending\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m         \u001b[38;5;28mnext\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Run and see the AI make intelligent decisions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m__end__\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m📊 Current State: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstep\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ds/pro/smart-meeting-copilot/smartcopilot-api/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mintelligent_supervisor\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     12\u001b[39m system_prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33mYou are an intelligent workflow supervisor using ReAct (Reasoning + Acting) methodology. \u001b[39m\n\u001b[32m     14\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \u001b[33mUse the ReAct process: THOUGHT → OBSERVATION → ACTION with clear reasoning.\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Format the prompt with current state\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m doc_preview = state[\u001b[33m'\u001b[39m\u001b[33mdocument_content\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m100\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdocument_content\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m) > \u001b[32m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m state[\u001b[33m'\u001b[39m\u001b[33mdocument_content\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     61\u001b[39m formatted_prompt = system_prompt.format(\n\u001b[32m     62\u001b[39m     doc_preview=doc_preview,\n\u001b[32m     63\u001b[39m     summary_status=state[\u001b[33m'\u001b[39m\u001b[33msummary_status\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     error_msg=state[\u001b[33m'\u001b[39m\u001b[33merror_message\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m )\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Setup Groq API with Qwen model\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'document_content'",
      "During task with name 'intelligent_supervisor' and id 'b5468e04-12a3-6c48-cd90-54d67c72e98a'"
     ]
    }
   ],
   "source": [
    "# --- Test the intelligent workflow ---\n",
    "print(\"🚀 Starting Intelligent Meeting Processing Workflow\")\n",
    "\n",
    "    # A. Store the initial document and get its ID\n",
    "    document_text = \"Meeting Minutes - July 22, 2025\\nAttendees: Alice, Bob, Charlie\\n1. Project Phoenix: Bob confirmed the server is deployed. Action Item: Charlie to schedule a budget review by Friday.\\n2. Marketing: The 'Summer Sale' will launch on August 1st. Action Item: AI team to refine the BERT chatbot for user intent by July 28th.\"\n",
    "    doc_id = DataStorage.store('document_content', document_text)\n",
    "\n",
    "    # B. Define the initial state using the ID\n",
    "    initial_state = {\n",
    "        \"document_content_id\": doc_id,\n",
    "        \"summary_output_id\": None,\n",
    "        \"insights_output_id\": None,\n",
    "        \"action_items_ids\": [],\n",
    "        \"iteration\": 0,\n",
    "        \"error_message\": None,\n",
    "        \"current_reasoning\": \"\",\n",
    "        \"next\": \"\"\n",
    "    }\n",
    "\n",
    "    # C. Run the workflow and capture the final state\n",
    "    final_state = {}\n",
    "    for step in app.stream(initial_state, {\"recursion_limit\": 10}):\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(f\"STEP: {list(step.keys())[0]}\")\n",
    "        print(f\"STATE: {step[list(step.keys())[0]]}\")\n",
    "        final_state = step[list(step.keys())[0]]\n",
    "\n",
    "    print(\"\\n🎯 Workflow completed with AI supervision!\")\n",
    "\n",
    "    # D. Retrieve and display the final results from DataStorage\n",
    "    print(\"\\n\\n--- FINAL RESULTS ---\")\n",
    "    summary = DataStorage.retrieve('summary_output', final_state.get('summary_output_id', ''))\n",
    "    insights = DataStorage.retrieve('insights_output', final_state.get('insights_output_id', ''))\n",
    "    \n",
    "    print(\"\\n✅ Final Summary:\")\n",
    "    print(summary or \"Not generated.\")\n",
    "    \n",
    "    print(\"\\n✅ Final Insights:\")\n",
    "    print(insights or \"Not generated.\")\n",
    "\n",
    "    print(\"\\n✅ Extracted Action Items:\")\n",
    "    for item_id in final_state.get('action_items_ids', []):\n",
    "        action_items = DataStorage.retrieve('action_items', item_id)\n",
    "        if action_items:\n",
    "            for i, item in enumerate(action_items):\n",
    "                print(f\"  - Task: {item.task}, Owner: {item.owner}, Deadline: {item.deadline}\")\n",
    "        else:\n",
    "            print(\"  - Could not retrieve action items.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43304e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d661ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f6160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     # This is a simple test to show how the node works in isolation\n",
    "    test_state = GraphState(\n",
    "        document_content=\"Meeting Minutes - July 21, 2025\\nAttendees: Alice, Bob, Charlie\\n1. Project Phoenix Update: Bob confirmed the new server is deployed. Alice raised a concern about the budget overrun. It was decided to review the Q3 budget next week. Action Item: Charlie to schedule a budget review meeting by Friday, July 25th.\\n2. Marketing Campaign: Discussed the new 'Summer Sale' campaign. It will launch on August 1st. All assets are ready.\",\n",
    "        summary_status=\"pending\",\n",
    "        insights_status=\"pending\",\n",
    "        summary_output=\"\",\n",
    "        insights_output=\"\",\n",
    "        iteration=0,\n",
    "        error_message=\"\",\n",
    "        current_reasoning=\"\",\n",
    "        next=\"\"\n",
    "    )\n",
    "\n",
    "    result_update = run_summary_agent_agentic(test_state)\n",
    "    print(\"\\n--- TEST RESULT ---\")\n",
    "    import json\n",
    "    print(json.dumps(result_update, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cf294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0919dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b012c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32c5b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Keep your original agent functions - they're fine\n",
    "# def run_summary_agent(state: GraphState) -> GraphState:\n",
    "#     \"\"\"Summary agent - focused on meeting summary\"\"\"\n",
    "#     print(f\"\\n📝 Summary Agent working on meeting minutes...\")\n",
    "#     new_state = state.copy()\n",
    "    \n",
    "#     # Simulate work with some intelligence about content\n",
    "#     success_rate = 0.1 if \"meeting\" in state['document_content'].lower() else 0.3\n",
    "    \n",
    "#     if random.random() < success_rate:\n",
    "#         new_state['summary_status'] = \"success\"\n",
    "#         new_state['summary_output'] = f\"Meeting Summary: Key decisions and action items extracted from meeting minutes (iteration {state['iteration']})\"\n",
    "#         print(\"✅ Summary: Generated meeting summary successfully\")\n",
    "#     else:\n",
    "#         new_state['summary_status'] = \"failed\" \n",
    "#         new_state['summary_output'] = \"Summary generation failed\"\n",
    "#         new_state['error_message'] = \"Temporary API issue during summary generation\"\n",
    "#         print(\"❌ Summary: Failed (likely temporary issue)\")\n",
    "    \n",
    "#     time.sleep(1)\n",
    "#     return new_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91540ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def run_insights_agent(state: GraphState) -> dict:\n",
    "#     \"\"\"\n",
    "#     Insights agent - focused on meeting insights.\n",
    "#     FIX: Now returns a dictionary and clears the error message on success.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n🔍 Insights Agent extracting key insights...\")\n",
    "    \n",
    "#     # Simulate work\n",
    "#     success_rate = 0.6 if \"meeting\" in state['document_content'].lower() else 0.3\n",
    "#     time.sleep(1)\n",
    "\n",
    "#     if random.random() < success_rate:\n",
    "#         print(\"✅ Insights: Extracted meeting insights successfully\")\n",
    "#         # On success, return a success status AND an empty error message\n",
    "#         return {\n",
    "#             \"insights_status\": \"success\",\n",
    "#             \"insights_output\": f\"Meeting Insights: Key themes and decisions identified (iteration {state['iteration']})\",\n",
    "#             \"error_message\": \"\"\n",
    "#         }\n",
    "#     else:\n",
    "#         print(\"❌ Insights: Failed (simulating temporary issue)\")\n",
    "#         # On failure, return a failed status AND a descriptive error message\n",
    "#         return {\n",
    "#             \"insights_status\": \"failed\",\n",
    "#             \"insights_output\": \"Insights generation failed\",\n",
    "#             \"error_message\": \"Temporary processing issue during insights extraction\"\n",
    "#         }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartcopilot-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
